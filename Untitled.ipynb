{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2434_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PARAMETERS:\n",
    "\n",
    "k - number of topics\n",
    "N - number of words in a document (different for each document)\n",
    "M - number of documents in a corpus\n",
    "\n",
    "Model parameters:\n",
    "z_n - [k] dimension vector; topic distribution for word n \n",
    "Theta - [k] dimension vector; mixture weights\n",
    "alpha - [k] dimension vector; prior probability for theta (mixture weights) (alpha > 0)\n",
    "beta - [k x V] dimension matrix; beta_ij = p(w^j = 1 | z^i = 1) \n",
    "                                 probability for a specific word j given a specific topic i\n",
    "D - list of [V x N] dimension matrices, that is M long = [\\mathbf{w}_1, ... \\mathbf{w}_M];\n",
    "                                 where \\mathbf{w} = [w_1,...,w_N] is [V x N] (one document consisting of N words) \n",
    "\n",
    "\n",
    "Variational parameters:\n",
    "Gamma - [k] dimension vector; determines Theta in the Variational Model\n",
    "Phi = phi_1 .. phi_N - [N x k] dimension matrix; determines the probability distribution \n",
    "                                 for topics z of words in the Variational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import special, misc\n",
    "from scipy.special import logsumexp\n",
    "from scipy.special import digamma, gammaln, polygamma\n",
    "import pandas as pd\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Document Corpus\n",
    "Download the data from \n",
    "https://github.com/Blei-Lab/lda-c/blob/master/example/ap.tgz\n",
    "\n",
    "We can directly load the file \"ap.dat\" which contains:\n",
    "\n",
    "1 line = 1 document,\n",
    "\n",
    "[number of different words in doc] [word index (where the one is in w_n]:[how often it occurs in the doc] [word index 2]:[occurences 2] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.genfromtxt('ap/vocab.txt',  dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data(corpus_file, vocabulary_file, stopwords_file):\n",
    "    \"\"\"\n",
    "    Reads the corpus from the .txt file into a list of lists;\n",
    "    a list for each document which contains a list of all the \n",
    "    words as strings.\n",
    "    Input parameters:\n",
    "    corpus_file - path to the corpus file\n",
    "    vocabulary_file - path to the vocabulary file\n",
    "    stopwords_file - path to the stopwords file\n",
    "    \"\"\"\n",
    "    vocabulary = np.genfromtxt(vocabulary_file,  dtype='str')\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "    corpus = []\n",
    "    \n",
    "    # read in stopwords from file into a list\n",
    "    stopwords = [] \n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stop_words = file.read().replace(',', ' ')\n",
    "        for word in stop_words.split():\n",
    "            stopwords.append(word) \n",
    "    \n",
    "    with open(corpus_file, 'r') as text:\n",
    "        doc = ''\n",
    "        new = False\n",
    "        for line in text:\n",
    "            if new: # reached a new document\n",
    "                if line.strip() != '</TEXT>': # until we reach the new doc\n",
    "                    for char in special_chars: # remove punctuation etc,\n",
    "                        line = line.replace(char, '') \n",
    "                    doc += line\n",
    "                else: # we've reached a new doc again\n",
    "                    doc = doc.lower() # all words lowercase\n",
    "                    words = np.array(doc.split())\n",
    "                    # PETER EDIT: next two lines\n",
    "                    doc = [word for word in words if (  (word not in stopwords) and (word in vocabulary)  )]\n",
    "                    corpus.append(doc)\n",
    "                    doc = ''\n",
    "            elif line.strip() == '<TEXT>': new = True\n",
    "\n",
    "    \n",
    "    return corpus, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocabulary = clean_up_data('ap/ap.txt', 'ap/vocab.txt', 'ap/stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(documents, vocabulary, k):\n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    # Initialize alpha \n",
    "    # alpha = np.ones([M,k]) * 50/k # for every document, for every topic\n",
    "    alpha = np.ones(k)*50/k\n",
    "    eta = 5/k\n",
    "    \n",
    "    Lambda = np.random.rand(k,V) * 0.5 + 0.5\n",
    "    \n",
    "    # Initialize beta\n",
    "    beta = np.zeros([k,V]) # for every topic, for every word in the vocabulary\n",
    "    for i in range(k):\n",
    "        beta[i] = np.random.uniform(0, 1, V)\n",
    "        beta[i] = beta[i] / np.sum(beta[i])\n",
    "    \n",
    "    # Initialize phi and gamma\n",
    "    phi = []\n",
    "    gamma = np.zeros([M,k]) # for every document, for every topic\n",
    "    for m in range(M):\n",
    "        doc = np.array(documents[m])\n",
    "        N = len(doc)\n",
    "        phi.append(np.ones([N,k]) * 1/float(k)) # uniform over topics\n",
    "        \n",
    "        for i in range(k):\n",
    "            gamma[m][i] = alpha[i] + N/float(k)\n",
    "        #m += 1 # WHYYYYYYY?\n",
    "        \n",
    "    return alpha, eta, beta, gamma, phi, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary,k):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    k, V = beta.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        term_knvSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            \n",
    "            v = np.where(vocabulary == document[n])[0][0] # here w_n is not a vector\n",
    "            if beta[i,v] <= 0:\n",
    "                print(\"Error: beta[\"+i,v,\"]<=0\")\n",
    "            #L+= phi[n,i] * np.log(beta[i,v]) \n",
    "            term_knvSum += phi[n,i] * np.log(beta[i,v]) \n",
    "\n",
    "    #print(term0,term_knSum, term_kSum)\n",
    "    L_terms = term0 + term_knSum + term_kSum + term_knvSum\n",
    "    \n",
    "    return L_terms\n",
    "    \n",
    "\n",
    "\n",
    "def psi(gamma_i):\n",
    "    # this is the first derivative (via Taylor approximation) of the log \\Gamma function\n",
    "    # according to Wikipedia this is the \"digamma\" function\n",
    "    return scipy.special.digamma(gamma_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDocumentLikelihood(wd, alpha, eta, gamma, digamma_gamma, phi, digamma_lambda, d):\n",
    "\n",
    "    V, K = digamma_lambda.shape\n",
    "    N = len(wd)\n",
    "    \n",
    "    E_theta_alpha = gammaln(alpha*K) - K * gammaln(alpha) \\\n",
    "                        + (alpha-1) * np.sum(digamma_gamma)\n",
    "    \n",
    "    E_z_theta = np.dot(np.sum(phi[d][:N,:], axis = 0), digamma_gamma)\n",
    "    \n",
    "    E_w_z_beta = np.sum(digamma_lambda[d,:] * phi[d][:N,:])\n",
    "    \n",
    "    E_theta_gamma = gammaln(np.sum(gamma[d,:])) - np.sum(gammaln(gamma[d,:])) \\\n",
    "                    + np.dot(gamma[d,:] - 1, digamma_gamma)\n",
    "\n",
    "    E_z_phi = np.sum(phi[d][:N,:] * np.log(phi[d][:N,:]))\n",
    "    \n",
    "\n",
    "    Likelihood = E_theta_alpha + E_z_theta + E_w_z_beta - E_theta_gamma - E_z_phi\n",
    "    return(Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_smoothed(documents, alpha, eta, gamma, phi, Lambda):\n",
    "    \n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda.T) - digamma(np.sum(Lambda, axis = 1))\n",
    "    likelihood = np.zeros([D,1])\n",
    "    \n",
    "    for d in range(D):\n",
    "        digamma_gamma = digamma(gamma[d,:]) - digamma(np.sum(gamma[d,:]))\n",
    "\n",
    "        N = len(documents[d])\n",
    "        E_theta_alpha = gammaln(alpha*K) - K * gammaln(alpha) \\\n",
    "                            + (alpha-1) * np.sum(digamma_gamma)\n",
    "        E_z_theta = np.dot(np.sum(phi[d][:N,:], axis = 0), digamma_gamma)\n",
    "        E_w_z_beta = np.sum(digamma_lambda[d,:] * phi[d][:N,:])\n",
    "        E_theta_gamma = gammaln(np.sum(gamma[d,:])) - np.sum(gammaln(gamma[d,:])) \\\n",
    "                        + np.dot(gamma[d,:] - 1, digamma_gamma)\n",
    "        E_z_phi = np.sum(phi[d][:N,:] * np.log(phi[d][:N,:]))\n",
    "        \n",
    "        likelihood = E_theta_alpha + E_z_theta + E_w_z_beta - E_theta_gamma - E_z_phi\n",
    "\n",
    "        E_beta_eta = K * (gammaln(eta * V) - V * gammaln(eta)) + (eta - 1) * np.sum(digamma_lambda)\n",
    "        E_beta_lambda = np.sum(gammaln(np.sum(Lambda, axis = 1)) - np.sum(gammaln(Lambda), axis = 1)[np.newaxis,:]) \\\n",
    "                        + np.sum((Lambda - 1) * digamma_lambda.T)\n",
    "    \n",
    "    likelihood = np.sum(likelihood) + E_beta_eta - E_beta_lambda\n",
    "    \n",
    "    return(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma(k, phi, gamma, alpha, beta, document, vocabulary, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    iterations = 0\n",
    "    converged = False\n",
    "    \n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (iterations < MAX_STEPS):\n",
    "        iterations += 1\n",
    "            \n",
    "        phi_old = phi\n",
    "        phi = np.zeros([N,k])\n",
    "        gamma_old = gamma\n",
    "            \n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                for i in range(k):                \n",
    "                    beta_ = beta[i, np.where(vocabulary == word)]\n",
    "                    phi[n, i] = beta_[0][0] * np.exp(digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "                phi[n,:] = phi[n,:] / np.sum(phi[n,:])   \n",
    "        gamma = alpha + np.sum(phi, axis=0)    \n",
    "            \n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print(str(iterations) + ' iterations to converge.')\n",
    "                \n",
    "            likelihood += compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k)\n",
    "            converged = True\n",
    "    \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma_smoothed(documents, alpha, eta, gamma, phi, Lambda, tol = 1e-4, MAX_STEPS = 100):\n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda.T) - digamma(np.sum(Lambda, axis = 1))\n",
    "    for d in range(D):\n",
    "        likelihood = -1e9\n",
    "        converged = False\n",
    "        iterations = 0\n",
    "        \n",
    "        while(not converged):\n",
    "\n",
    "            iterations += 1\n",
    "            wd = documents[d]\n",
    "            \n",
    "            digamma_gamma = digamma(gamma[d,:]) - digamma(np.sum(gamma[d,:]))\n",
    "            \n",
    "            N = len(documents[d])\n",
    "            \n",
    "            phi[d][:N,:] = digamma_gamma + digamma_lambda[d,:]\n",
    "            #Yasmin changed misc.logsumexp to special.logsumexp\n",
    "            phi[d][:N,:] = np.exp(phi[d][:N,:] - special.logsumexp(phi[d][:N,:], axis = 1)[:,np.newaxis])\n",
    "            \n",
    "            gamma[d,:] = alpha + np.sum(phi[d][:N,:], axis = 0)\n",
    "            \n",
    "            newLikelihood = ComputeDocumentLikelihood(wd, alpha, eta, gamma, digamma_gamma, phi, digamma_lambda, d)\n",
    "            dlikelihood = abs((newLikelihood - likelihood)/likelihood)\n",
    "            likelihood = newLikelihood\n",
    "            \n",
    "            if(dlikelihood < tol).any():\n",
    "                converged = True\n",
    "    \n",
    "    #print gamma\n",
    "    return(phi, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(phi, eta, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    Lambda = np.ones([k, V]) * eta\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int)  \n",
    "                Lambda[i][j] += np.dot(indicator, phi_)\n",
    "                    \n",
    "    return Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(phi, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = np.zeros([k, V])\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                beta[i][j] += np.dot(indicator, phi_)\n",
    "    beta = np.transpose(np.transpose(beta) / np.sum(beta, axis=1))\n",
    "\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha, gamma, k, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "    # Maria B version\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = M * (k * special.polygamma(1, alpha) - special.polygamma(1, k*alpha))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = M * k * (k * special.polygamma(2, k*alpha) - special.polygamma(2, alpha))\n",
    "\n",
    "    temp = gradient / (hessian * alpha + gradient + tol)\n",
    "    if (alpha == 0).any():\n",
    "        alpha += 0.005\n",
    "\n",
    "    log_alpha = np.log(alpha) - temp\n",
    "    alpha = np.exp(log_alpha)    \n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eta(eta, gamma, k, V, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = V * (k * special.polygamma(1, eta) - special.polygamma(1, k*eta))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = V * k * (k * special.polygamma(2, k*eta) - special.polygamma(2, eta))\n",
    "\n",
    "    temp = gradient / (hessian * eta + gradient + tol)\n",
    "    if (eta == 0):\n",
    "        eta += 0.005\n",
    "\n",
    "    log_eta = np.log(eta) - temp\n",
    "    eta = np.exp(log_eta)    \n",
    "        \n",
    "    return eta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(phi, gamma, alpha, beta, documents, vocabulary, k):\n",
    "\n",
    "    for d, doc in enumerate(documents):\n",
    "        phi[d], gamma[d], likelihood = update_phi_gamma(k, phi[d], gamma[d], alpha, beta, doc, vocabulary)\n",
    "                \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step_smoothed(documents, alpha, eta, gamma, phi, Lambda, Tol = 1e-5, MAX_STEPS = 100):\n",
    "\n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    iterations = 0\n",
    "    likelihood = -1e9\n",
    "    converged = False\n",
    "    while(not(converged)):\n",
    "        \n",
    "        iterations += 1\n",
    "        phi, gamma = update_phi_gamma_smoothed(documents, alpha, eta, gamma, phi, Lambda)\n",
    "        Lambda = update_lambda(phi, eta, documents, vocabulary, k)\n",
    "\n",
    "\n",
    "        newLikelihood = compute_likelihood_smoothed(documents, alpha, eta, gamma, phi, Lambda)\n",
    "        dlikelihood = abs((newLikelihood - likelihood)/likelihood)\n",
    "        likelihood = newLikelihood\n",
    "\n",
    "        if(dlikelihood < Tol).any():\n",
    "            print('E-step converged after %d iterations' %iterations)\n",
    "            converged = True\n",
    "    return(phi, gamma, Lambda, likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(phi, gamma, alpha, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    beta = update_beta(phi, documents, vocabulary, k)\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    eta = update_eta(eta, gamma, k, V, M)\n",
    "    print(\"NEW DEBU\")\n",
    "    print(eta)\n",
    "    \n",
    "    return alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM(phi_init, gamma_init, alpha_init, beta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "    \n",
    "        phi, gamma, likelihood = \\\n",
    "            E_step(phi_old, gamma_old, alpha_old, beta_old, documents, vocabulary, k)\n",
    "        alpha, Beta = \\\n",
    "            M_step(phi, gamma, alpha_old, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, alpha, Beta, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    Lambda = Lambda_init\n",
    "    eta = eta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "        Lambda_old = Lambda\n",
    "        eta_old = eta\n",
    "        \n",
    "    \n",
    "        phi, gamma, Lambda, likelihood = \\\n",
    "            E_step_smoothed(documents, alpha_old, eta_old, gamma_old, phi_old, Lambda_old)\n",
    "        alpha, eta = \\\n",
    "            M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, Lambda, alpha, eta, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "corpus_reduced = corpus[:4]\n",
    "M = len(corpus_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "42 iterations to converge.\n",
      "39 iterations to converge.\n",
      "41 iterations to converge.\n",
      "35 iterations to converge.\n",
      "M-step\n",
      "49 iterations to converge.\n",
      "42 iterations to converge.\n",
      "51 iterations to converge.\n",
      "41 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, alpha, beta, likelihood = \\\n",
    "        variational_EM(phi_init, gamma_init, alpha_init, beta_init, corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: smoothed LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "E-step converged after 16 iterations\n",
      "M-step\n",
      "NEW DEBU\n",
      "1.0352422730586692\n",
      "E-step converged after 18 iterations\n",
      "M-step\n",
      "NEW DEBU\n",
      "0.6663281132982769\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, Lambda, alpha, eta, likelihood = \\\n",
    "variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, corpus_reduced, vocabulary, k, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03524227, 1.14718878, 1.04989747, ..., 1.03524227, 1.03524227,\n",
       "        1.03524227],\n",
       "       [1.03524227, 2.81134468, 2.00593172, ..., 1.03524227, 1.03524227,\n",
       "        1.03524227],\n",
       "       [1.03524227, 1.14719335, 1.04989763, ..., 1.03524227, 1.03524227,\n",
       "        1.03524227]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x20260ca0e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAbG0lEQVR4nO3de7QlZX3m8e/TTdMQIAI2YAutYMRk0FHEFmHMyuBtQDR0ohDbSRQUVycGlrpwJkFnxetyImspJoqB1YyMTeIFFt5aB+SmjsYo2BBuTcvYMURaOmCDclGC9DnP/FF1ZGezL3XO2bV37eL5uGqdury76tcl+3fe89b7viXbRETE9Fsy6QAiImI0ktAjIloiCT0ioiWS0CMiWiIJPSKiJZLQIyJaoraELmk3SddKulHSZknv7VFmuaSLJG2VdI2kg+uKJyKi7eqsoT8MvNj2c4DDgeMkHdVV5lTgp7afDnwEOKvGeCIiWq22hO7Cg+XmsnLpHsW0BthQrl8CvESS6oopIqLNdqnz5JKWAtcBTwc+bvuariIHAncA2N4p6T7gicCOrvOsA9YBaNmuz9ttn/3rDHtq7HL3zycdQjSQluTR2Jz7Z+/ZYXu/xZzj2Bft4XvunalU9rqbHr7c9nGLud5i1JrQbc8Ah0vaG/iCpGfZvqWjSK/a+GPmIrC9HlgP8GsHrPLT//CMWuKdNgf81T9MOoTG0NKlkw6hMbR8+aRDaIwrfn7hvyz2HPfcO8O1lz+lUtmlK3+wYrHXW4yx/Cq3/TPgG0D3b65twCoASbsATwDuHUdMERFVGJit+L9Jq7OXy35lzRxJuwMvBb7fVWwjcHK5fiLwNWe2sIhoEGMe8UylZdLqbHJZCWwo29GXABfb/oqk9wGbbG8EPgH8raStFDXztTXGExGxIE2ofVdRW0K3fRPw3B7739Wx/m/ASXXFEBGxWMbMTEnDQa0PRSMi2mD2sX01GikJPSJiAAMzSegREe2QGnpERAsYeCRt6BER0884TS4REa1gmJmOfJ6EHhExSDFSdDokoUdEDCRmek471TxJ6BERAxQPRZPQIyKmXtEPPQk9IqIVZqekhp6Z8CMiBpiroVdZBpG0StLXJW0p37P81nL/eyT9WNIN5XJ8x2feUb5z+TZJxw6LNTX0iIgBjJgZTd13J/B229dL2gu4TtKV5bGP2P5QZ2FJh1HMQPtM4MnAVZKeUb44qKck9IiIIUbR5GJ7O7C9XH9A0haK13D2swb4rO2HgX8upxk/EvhOvw+kySUiYgAjfumllRZghaRNHcu6XueUdDDF9OJz71k+XdJNki6QtE+571fvXC5tY/AvgNTQIyIGKQYWVa777rC9elABSXsCnwPeZvt+SecC7y8v9X7gw8AbqfjO5U5J6BERQ4yq26KkZRTJ/FO2Pw9g+66O4+cDXyk3f/XO5dJBwJ2Dzp8ml4iIAWwx4yWVlkEkieK1m1tsn92xf2VHsd8HbinXNwJrJS2XdAhwKHDtoGukhh4RMcTsaGroLwReB9ws6YZy3zuB10o6nKI55XbgjwFsb5Z0MXArRQ+Z0wb1cIEk9IiIgYqHootPlbb/nt7t4pcO+MwHgA9UvUYSekTEAPN8KDpRSegREUPMTMnQ/yT0iIgBRjhStHZJ6BERQ8wO6cHSFEnoEREDFJNzJaFHREw9Ix4phvU3XhJ6RMQANkMHDTVFbVH2m/u3q8wxku7rmAf4XXXFExGxMGK24jJpddbQe879a/vWrnLfsv3KGuOIiFgwMz019NoS+oC5f7sTekREo03LQ9GxRNlj7t9OR0u6UdJlkp45jngiIqoyYtbVlkmr/aFo99y/XYevB55q+8HyPXpfpJhRrPsc64B1AMv22qf7cEREbQw8MoK5XMah1hp6r7l/O9m+3/aD5fqlwDJJK3qUW297te3Vu+y+R50hR0R0qfaC6FHNmb4Ytf3a6Tf3b1eZJwF32bakIyl+wdxTV0wREfNlMlIU+s/9+xQA2+cBJwJvlrQTeAhYa3vgK5YiIsatCbXvKurs5dJv7t/OMucA59QVQ0TEYtlKDT0iog2Kh6IZ+h8R0QLKwKKIiDYoHoo+ztvQIyLaYlpGiiahR0QMMDdSdBokoUdEDJGXREdEtIANj8wmoUdETL2iySUJPSKiFR73I0UjItog3RYjIlojTS4REa3RhPeFVpGEHhExQNHLJXO5RERMvQwsiohokTS5RES0QHq5RES0yLT0cpmOKCMiJsQWO72k0jKIpFWSvi5pi6TNkt5a7t9X0pWSflD+3KfcL0kflbRV0k2SjhgWaxJ6RMQQs1alZYidwNtt/wfgKOA0SYcBZwJX2z4UuLrcBng5cGi5rAPOHXaBJPSIiAHm2tAXm9Btb7d9fbn+ALAFOBBYA2woi20Afq9cXwNc6MJ3gb0lrRx0jbShR0QMMY+HoiskberYXm97fXchSQcDzwWuAQ6wvR2KpC9p/7LYgcAdHR/bVu7b3u/iSegREQPMsx/6DturBxWQtCfwOeBttu+X+p671wEPOneaXCIihphFlZZhJC2jSOafsv35cvddc00p5c+7y/3bgFUdHz8IuHPQ+ZPQIyIGsGHn7JJKyyAqquKfALbYPrvj0Ebg5HL9ZOBLHftfX/Z2OQq4b65ppp80uUREDDGigUUvBF4H3CzphnLfO4EPAhdLOhX4EXBSeexS4HhgK/AL4A3DLpCEHhExwKjmcrH99/RuFwd4SY/yBk6bzzWS0CMihnCG/kdEtMO0TM5V20PRfsNcu8rMe2hrRMQ42SMbKVq7Omvoc8Ncr5e0F3CdpCtt39pRpnNo6wsohra+oMaYIiLmScwM6cHSFLVFOWCYa6d5D22NiBg3W5WWSRtLG3rXMNdOlYa2SlpHMTkNy3fbm31v/WVdoU6Vy++8cdIhNMbnfr7XpENojLP/6WWTDqE5jl38KaZpPvTa/47oHubafbjHRx4ztNX2eturba9etusedYQZEdGbi3b0Ksuk1VpD7zPMtdO8h7ZGRIxbern0H+baad5DWyMixsnlQ9Eqy6TVWUPvN8z1KQC2z2MBQ1sjIsatCc0pVdSW0IcMc50rM++hrRER49aEHixVZKRoRMQAxQPPJPSIiFaYlm6LSegREUM87tvQIyLawIjZBvRgqSIJPSJiiCmpoCehR0QMlIeiEREtMiVV9CT0iIghWl1Dl7Tc9sOjDiYiomkMzM5OR0If+uhW0gVd23tSDNmPiGg/A1a1ZcKq9MX5saRzASTtA1wB/F2tUUVENMi0TJ87NKHb/gvgfknnUSTzD9v+37VHFhHRFK64TFjfNnRJr+rYvBb4i/KnJb2qz/zmEREt04zXy1Ux6KHo73Zt/yOwrNxvIAk9Ih4fGlD7rqJvQreduckjIgxuSy+XXiS9ctSBREQ0lyouk7XQGWeeP9IoIiKabNofig5i+92jDiQiorEakKyrWGiTy5NGHUhERCO1bGBRL58YaRQREQ02LQOLFtrk8opRBxIR0VhT0stloZNz7Wn7wVEHExHRRGpA7buKhTa53DrSKCIimqpqD5cKSV/SBZLulnRLx773SPqxpBvK5fiOY++QtFXSbZKOHXb+QUP/z+h3CNhzeOgREW0w0geenwTOAS7s2v8R2x/6d1eVDgPWAs8EngxcJekZtmf6nXxQDf1/AvsAe3Utew75XEREu4yohm77m8C9Fa+6Bvis7Ydt/zOwFThy0AcGtaFfD3zR9nXdByS9qWJAERHTb7ZyyRWSNnVsr7e9vsLnTpf0emAT8HbbPwUOBL7bUWZbua+vQQn9DcA9fY6trhBgRMT0m+uHXs0O2/PNj+cC7y+v9H7gw8Ab6T2XwMC/A/o2ndi+zfaOPsfuGhZhr8b/ruPHSLqv40HAu4adMyJiEuRqy0LYvsv2jO1Z4HwebVbZBqzqKHoQcOegc9XZFv5J4LghZb5l+/ByeV+NsURELFyNc7lIWtmx+fvAXCV4I7BW0nJJhwCHUryToq8F9UOvwvY3JR1c1/kjIqaNpM8Ax1C0tW8D3g0cI+lwil8JtwN/DGB7s6SLKbqJ7wROG9TDBWpM6BUdLelGij8j/pvtzb0KSVoHrANYvtveYwwvImJ0A4tsv7bH7r5Tqdj+APCBqucf2uQiaYOkvTu295F0QdULDHA98FTbzwE+BnyxX0Hb622vtr162a57jODSEREVmWLof5Vlwqq0oT/b9s/mNsruNM9d7IVt3z83fYDtS4FlklYs9rwRESM3JfOhV0noSyTtM7chaV9G0FQj6UmSVK4fWcbSr5tkRMTE1NnLZZSqJOYPA/8g6ZJy+yQqtOn0afxfBmD7POBE4M2SdgIPAWvtJkxAGRHRZUoy09CEbvvCcuTTiyk6ur/K9tDJufo0/nceP4diToOIiGab9oQu6ddt3182sfwr8OmOY/varjofQUTE1GpKc0oVg2ronwZeCVxH8fup8xGugafVGFdERHM0oAdLFX0Tuu1Xlj8PGV84ERHN04Ya+q9IehXw2xQ182/Z7ttnPCKiddqS0CX9DfB04DPlrj+R9DLbp9UaWUREE7SkDX3OfwaeNdelUNIG4OZao4qIaJIpSehVBhbdBjylY3sVcFM94URENI9mqy2TVqWG/kRgi6S5aRufD3xH0kYA2yfUFVxERFRXJaHnxRMR8fg2JU0uVUaK/l9JB1DUzAGutX13vWFFRDTEFD0UrTJ97h9QvCXjJOAPgGsknVh3YBERjTElsy1WaXL5H8Dz52rlkvYDrgIuGfipiIi2aECyrqJKQl/S1cRyD/W+izQiojFEM3qwVFEloX9V0uU8OrDoNcBl9YUUEdEgU9SGXuWh6H/vGPovYL3tL9QeWUREU7QloUs6y/afA5/vsS8iov2mJKFXaQt/WY99Lx91IBERTTX1r6CT9GbgT4GnSeoc6r8X8O26A4uIaIwGJOsqhr3g4jLgL4EzO/Y/kLcVRcTjhlvQy8X2fcB9wMB3g0ZEtF4LaugREUEz2serSEKPiBgmCT0iogUaMk9LFUnoEREDiDS5RES0RhJ6RERbJKFHRLTElCT02qbBlXSBpLsl3dLnuCR9VNJWSTdJOqKuWCIiFqzisP8qzTK98qKkfSVdKekH5c99yv3zzpF1zmv+SeC4AcdfDhxaLuuAc2uMJSJi4Ub3xqJP8ti8eCZwte1Dgat5dGT+vHNkbQnd9jeBQVMErAEudOG7wN6SVtYVT0TEQmm22jJMn7y4BthQrm8Afq9j/7xy5CTfPHQgcEfH9rZy32NIWidpk6RNj/zy52MJLiJizjyaXFbM5apyWVfh9AfY3g5Q/ty/3F85R86Z5ENR9djX848W2+uB9QC/dsAq33vYrnXGNTWOffJzJh1CY2jp0kmH0Bi/vnz7pENol/kNLNphe/WIrlw5R86ZZA19G7CqY/sg4M4JxRIR0d/o2tB7uWuuKaX8OfcO53nnyEkm9I3A68snuUcB98392RER0RRzI0VrfMHFRuDkcv1k4Esd++eVI2trcpH0GeAYijalbcC7gWUAts8DLgWOB7YCvwDeUFcsERGLodnRdETvkxc/CFws6VTgR8BJZfF558jaErrtgfOo2zZwWl3Xj4gYiRFOzjUgL76kR9l558iMFI2IGCJzuUREtEUSekREO6SGHhHRFknoEREt4GrD+psgCT0iYoC8sSgiok08HRk9CT0iYojU0CMi2mCEA4vqloQeETFEHopGRLREEnpERBuYPBSNiGiLPBSNiGiLJPSIiOmXgUUREW1hj+wFF3VLQo+IGGY68nkSekTEMGlyiYhoAwNpcomIaInpyOdJ6BERw6TJJSKiJdLLJSKiDTLbYkREOxQDi6YjoyehR0QMk9kWIyLaITX0iIg2mKI29CV1nlzScZJuk7RV0pk9jp8i6SeSbiiXN9UZT0TE/BVzuVRZJq22GrqkpcDHgZcB24DvSdpo+9auohfZPr2uOCIiFm1KmlzqrKEfCWy1/UPbvwQ+C6yp8XoREaPn4hV0VZZJqzOhHwjc0bG9rdzX7dWSbpJ0iaRVNcYTEbEwdrVlwupM6Oqxr/tf/GXgYNvPBq4CNvQ8kbRO0iZJm3Y+9PMRhxkRMYQrLhNWZ0LfBnTWuA8C7uwsYPse2w+Xm+cDz+t1Itvrba+2vXqX3feoJdiIiH40O1tpmbQ6E/r3gEMlHSJpV2AtsLGzgKSVHZsnAFtqjCciYv5MMbCoyjKEpNsl3Vz26ttU7ttX0pWSflD+3GehodaW0G3vBE4HLqdI1Bfb3izpfZJOKIu9RdJmSTcCbwFOqSueiIiFEEautlT0ItuH215dbp8JXG37UODqcntBah1YZPtS4NKufe/qWH8H8I46Y4iIWLR6H3iuAY4p1zcA3wD+fCEnqnVgUUREK1Tv5bJirgNHuazrPhNwhaTrOo4dYHt7cRlvB/ZfaJgZ+h8RMchcG3o1OzqaUnp5oe07Je0PXCnp+4sNr1MSekTEEKPqwWL7zvLn3ZK+QDEA8y5JK21vLzuK3L3Q86fJJSJioIrNLUPa2SXtIWmvuXXgvwC3UPT+O7ksdjLwpYVGmhp6RMQgZlQPRQ8AviAJitz7adtflfQ94GJJpwI/Ak5a6AWS0CMihhlBi4vtHwLP6bH/HuAli79CEnpExFB5wUVERFskoUdEtIANM5Ofp6WKJPSIiGFSQ4+IaIkk9IiIFjDQgPeFVpGEHhExkMFpQ4+ImH4mD0UjIlojbegRES2RhB4R0QbDJ95qiiT0iIhBDDTgBdBVJKFHRAyTGnpERBtk6H9ERDsYnH7oEREtkZGiEREtkTb0iIgWsNPLJSKiNVJDj4hoA+OZmUkHUUkSekTEIJk+NyKiRaak2+KSOk8u6ThJt0naKunMHseXS7qoPH6NpIPrjCciYr4MeNaVlkmrLaFLWgp8HHg5cBjwWkmHdRU7Ffip7acDHwHOqiueiIgFcfmCiyrLhNVZQz8S2Gr7h7Z/CXwWWNNVZg2woVy/BHiJJNUYU0TEvHlmptIyaXW2oR8I3NGxvQ14Qb8ytndKug94IrCjs5CkdcC6cvPhmz9yxi21RDw/K+iKc9xubkAMpcnHsbMBMRQmH0fuRaffXOwJHuCnl1/lS1ZULD7Rf2+dCb1XTbu7kalKGWyvB9YDSNpke/Xiw1ucJsTRhBiaEkcTYmhKHE2IoSlxSNq02HPYPm4UsYxDnU0u24BVHdsHAXf2KyNpF+AJwL01xhQR0Vp1JvTvAYdKOkTSrsBaYGNXmY3AyeX6icDX7CkZkhUR0TC1NbmUbeKnA5cDS4ELbG+W9D5gk+2NwCeAv5W0laJmvrbCqdfXFfM8NSGOJsQAzYijCTFAM+JoQgzQjDiaEMPYKBXiiIh2qHVgUUREjE8SekRESzQ2oTdh2oAKMZwi6SeSbiiXN9UQwwWS7pbUs++9Ch8tY7xJ0hGjjqFiHMdIuq/jXryrhhhWSfq6pC2SNkt6a48ytd6PijGM417sJulaSTeWcby3R5lavyMVY6j9O9JxraWS/lHSV3oce3xMM2K7cQvFQ9R/Ap4G7ArcCBzWVeZPgfPK9bXARROI4RTgnJrvxe8ARwC39Dl+PHAZRZ/+o4BrJhTHMcBXar4XK4EjyvW9gP/X4/+TWu9HxRjGcS8E7FmuLwOuAY7qKlP3d6RKDLV/RzqudQbw6V73vu570ZSlqTX0JkwbUCWG2tn+JoP75q8BLnThu8DeklZOII7a2d5u+/py/QFgC8Vo40613o+KMdSu/Pc9WG4uK5fuHg61fkcqxjAWkg4CXgH8rz5FHhfTjDQ1ofeaNqD7S/Pvpg0A5qYNGGcMAK8u/7S/RNKqHsfrVjXOcTi6/PP7MknPrPNC5Z/Mz6WoFXYa2/0YEAOM4V6UTQw3AHcDV9ruey9q+o5UiQHG8x35K+DPgH4zZNV+L5qgqQl9ZNMG1BzDl4GDbT8buIpHawDjVPd9qOp64Km2nwN8DPhiXReStCfwOeBttu/vPtzjIyO/H0NiGMu9sD1j+3CKUdhHSnpWd5i9PjbmGGr/jkh6JXC37esGFeuxr3V9tpua0JswbcDQGGzfY/vhcvN84HkjvH5VVe5V7WzfP/fnt+1LgWWSqk5oVJmkZRSJ9FO2P9+jSO33Y1gM47oXHdf7GfANoHvOkbFNrdEvhjF9R14InCDpdoqm0RdL+ruuMo+LaUaamtCbMG3A0Bi62mZPoGhPHbeNwOvL3h1HAffZ3j7uICQ9aa5NUtKRFP9t3TPia4hidPEW22f3KVbr/agSw5juxX6S9i7XdwdeCny/q1it35EqMYzjO2L7HbYPsn0wxff0a7b/qKvY42KakUa+gs71TRsw6hjeIukEYGcZwymjjAFA0mcoek2skLQNeDfFwydsnwdcStGzYyvwC+ANo46hYhwnAm+WtBN4CFhbwxfmhcDrgJvLdluAdwJP6Yij7vtRJYZx3IuVwAYVL5JZAlxs+yvj/I5UjKH270g/Y74XjZCh/xERLdHUJpeIiJinJPSIiJZIQo+IaIkk9IiIlkhCj4hoiST0qI2kmXKGvc3lMPgzJE3Ff3OSDpd0/KTjiJiPRvZDj9Z4qBwWjqT9KWbCewJFH/amOxxYTdGvPWIqpB961EbSg7b37Nh+GsUI3BXAcuBciqS5EzjD9tfLQSpnAcdSzLVxvu2PlcO6V9veIWk18CHbx0h6D3AIxSCXZ1BMoXoU8HLgx8Dv2n5E0vOAs4E9gR3AKba3S/oGxeRaLwL2Bk4tt7cCu5fn+EvgX4G/Lv8pBn6nnG0xojFSQ4+xsf3Dssllf+CPyn3/UdJvAVdIegbFyM5DgOeWo3X3rXDq36BIyIcB3wFebfvPJH0BeIWk/0MxSdYa2z+R9BrgA8Aby8/vYvvIsonl3bZfquKlFKttnw4g6cvAaba/XU7M9W8juSkRI5SEHuM2N+vdb1MkWWx/X9K/UNSwX0rxIoKd5bEqEyhdVtbCb6aYpuGr5f6bgYOB3wSeBVxZTrGyFOic32Vugq3ryvK9fBs4W9KngM/b3lYhroixSkKPsSmbXGYo5s7u93IB0Xta0508+hB/t65jDwPYnpX0SMe8KbMU/40L2Gz76D7XnJsNcIY+3wnbHyxr+scD35X0Utvdk2FFTNRU9DiI6SdpP+A8iteRGfgm8IflsWdQTG51G3AF8CflFKd0NLnczqNTr756npe/DdhP0tHlOZdVeOnEAxSvmJuL/zds32z7LGAT8FvzjCGidknoUafd57otUrzc4Apg7kXCfwMsLZtJLqJ4SPkwxSvEfgTcJOlG4L+W5d8L/LWkb1HUpCtz8QrBE4GzynPeAPynIR/7OnBYGf9rgLdJuqX8/EMU7y2NaJT0comIaInU0CMiWiIJPSKiJZLQIyJaIgk9IqIlktAjIloiCT0ioiWS0CMiWuL/AyPKUCCtno6IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(gamma.T)\n",
    "plt.xlabel(\"Documents\")\n",
    "plt.ylabel(\"topic 1..k\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolormesh(Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peres', 'teacher', 'school', 'students', 'liberace']\n",
      "['shot', 'israel', 'rappaport', 'police', 'mrs']\n",
      "['president', 'first', 'mrs', 'peres', 'police']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = beta[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-5:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TEXT WITH COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For three years Charles S Robb was out of the spotlight that had become so familiar first as the soninlaw of President Lyndon Johnson and then as Democratic governor of this conservative state But on Tuesday the yearold lawyer reentered the national arena in decisive style fashioning a huge victory over Republican longshot Maurice Dawkins a retired black minister and Washington lobbyist Robb said today he won because we attempted to identify with mainstream values that are crucial to success at the national level such as strong defense and fiscal responsibility With  percent of the precincts counted Robb had'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_text(corpus_file, number_of_text):\n",
    "    fulltext_words=[]\n",
    "    fulltext_allwords=[]\n",
    "    #number_of_text=2\n",
    "    text_counter=0\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "\n",
    "    with open(corpus_file, 'r') as text:\n",
    "        new=False\n",
    "        for line in text:\n",
    "            if new:\n",
    "                #print(line.strip()[0], line.strip()[:10])\n",
    "                if line.strip()[0]==\"<\":\n",
    "                    pass\n",
    "                else:\n",
    "                    #print(\"FOUND\", text)\n",
    "                    text_counter+=1\n",
    "                    if text_counter==number_of_text:\n",
    "                        #print(\" CORRECT\")\n",
    "                        new_text=line\n",
    "                        fulltext=new_text\n",
    "                        words = np.array(new_text.split())\n",
    "                        for word in words:\n",
    "                            fulltext_allwords.append(word)\n",
    "                            for char in special_chars: # remove punctuation etc,\n",
    "                                word = word.replace(char, '') \n",
    "                            fulltext_words.append(word)\n",
    "\n",
    "\n",
    "            else:\n",
    "                if line.strip() == \"<TEXT>\":\n",
    "                    new=True\n",
    "    return fulltext_words, fulltext_allwords\n",
    "\n",
    "fulltext_words, fulltext_allwords = get_full_text('ap/ap.txt', 13)\n",
    "\" \".join(fulltext_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['blue','green', 'red']\n",
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=2.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in vocabulary:\n",
    "        v = np.where(vocabulary==word)[0][0]\n",
    "        #print(v,word_beta )\n",
    "        word_beta = beta[:,v]\n",
    "        #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "        if np.max(word_beta)>np.mean(beta):\n",
    "            if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                color = colors[topic]\n",
    "                print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "            else:\n",
    "                color='k'\n",
    "        else:\n",
    "            color='k'\n",
    "    else: \n",
    "        color='k'\n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mFor \u001b[0mthree \u001b[0myears, \u001b[0mCharles \u001b[0mS. \u001b[0mRobb \u001b[0mwas \u001b[0mout \u001b[0mof \u001b[0mthe \u001b[0mspotlight \u001b[0mthat \u001b[0mhad \u001b[0mbecome \u001b[0mso \u001b[0mfamiliar, \u001b[0mfirst \u001b[0mas \u001b[0mthe \u001b[0mson-in-law \u001b[0mof \u001b[0mPresident \u001b[0mLyndon \u001b[0mJohnson \u001b[0mand \u001b[0mthen \u001b[0mas \u001b[0mDemocratic \u001b[0mgovernor \u001b[0mof \u001b[0mthis \u001b[0mconservative \u001b[0mstate. \u001b[0mBut \u001b[0mon \u001b[0mTuesday, \u001b[0mthe \u001b[0m49-year-old \u001b[0mlawyer \u001b[0mre-entered \u001b[0mthe \u001b[0mnational \u001b[0marena \u001b[0min \u001b[0mdecisive \u001b[0mstyle, \u001b[0mfashioning \u001b[0ma \u001b[0mhuge \u001b[0mvictory \u001b[0mover \u001b[0mRepublican \u001b[0mlong-shot \u001b[0mMaurice \u001b[0mDawkins, \u001b[0ma \u001b[0mretired \u001b[0mblack \u001b[0mminister \u001b[0mand \u001b[0mWashington \u001b[0mlobbyist. \u001b[0mRobb \u001b[0msaid \u001b[0mtoday \u001b[0mhe \u001b[0mwon \u001b[0mbecause \u001b[0m``we \u001b[0mattempted \u001b[0mto \u001b[0midentify \u001b[0mwith \u001b[0mmainstream \u001b[0mvalues \u001b[0mthat \u001b[0mare \u001b[0mcrucial \u001b[0mto \u001b[0msuccess \u001b[0mat \u001b[0mthe \u001b[0mnational \u001b[0mlevel,'' \u001b[0msuch \u001b[0mas \u001b[0mstrong \u001b[0mdefense \u001b[0mand \u001b[0mfiscal \u001b[0mresponsibility. \u001b[0mWith \u001b[0m99 \u001b[0mpercent \u001b[0mof \u001b[0mthe \u001b[0mprecincts \u001b[0mcounted, \u001b[0mRobb \u001b[0mhad \u001b[0m1,448,389 \u001b[0mvotes \u001b[0mor \u001b[0m71 \u001b[0mpercent, \u001b[0mto \u001b[0mDawkins' \u001b[0m587,887 \u001b[0mvotes \u001b[0mor \u001b[0m29 \u001b[0mpercent. \u001b[0mThe \u001b[0mformer \u001b[0mMarine \u001b[0mcombat \u001b[0mofficer \u001b[0mhas \u001b[0mbuilt \u001b[0ma \u001b[0mcareer \u001b[0mby \u001b[0mmaking \u001b[0mDemocrats \u001b[0melectable \u001b[0min \u001b[0mconservative \u001b[0mVirginia. \u001b[0mOnce \u001b[0mknown \u001b[0monly \u001b[0mas \u001b[0mthe \u001b[0mformer \u001b[0mWhite \u001b[0mHouse \u001b[0mmilitary \u001b[0msocial \u001b[0maide \u001b[0mwho \u001b[0mmarried \u001b[0mLBJ's \u001b[0mdaughter, \u001b[0mLynda \u001b[0mBird \u001b[0mJohnson, \u001b[0mhe \u001b[0mwon \u001b[0mthe \u001b[0mlieutenant \u001b[0mgovernor's \u001b[0mrace \u001b[0min \u001b[0m1977 \u001b[0min \u001b[0mhis \u001b[0mfirst \u001b[0mbid \u001b[0mfor \u001b[0melective \u001b[0moffice. \u001b[0mFour \u001b[0myears \u001b[0mlater, \u001b[0mhe \u001b[0mran \u001b[0mfor \u001b[0mgovernor \u001b[0min \u001b[0mthe \u001b[0mfirst \u001b[0msweep \u001b[0mby \u001b[0mDemocrats \u001b[0mof \u001b[0mthe \u001b[0mstate's \u001b[0mtop \u001b[0mthree \u001b[0moffices \u001b[0msince \u001b[0m1965. \u001b[0mRobb \u001b[0mwas \u001b[0ma \u001b[0mpopular \u001b[0mgovernor \u001b[0mwho \u001b[0mwas \u001b[0mcredited \u001b[0mwith \u001b[0moverhauling \u001b[0mthe \u001b[0mstate \u001b[0mbureaucracy \u001b[0mand \u001b[0mmaking \u001b[0mmajor \u001b[0mgains \u001b[0min \u001b[0meducation \u001b[0mfunding. \u001b[0mHe \u001b[0malso \u001b[0mopened \u001b[0mpositions \u001b[0mof \u001b[0mauthority \u001b[0min \u001b[0mstate \u001b[0mgovernment \u001b[0mto \u001b[0mblacks \u001b[0mand \u001b[0mwomen \u001b[0mand \u001b[0mappointed \u001b[0mVirginia's \u001b[0mfirst \u001b[0mblack \u001b[0mSupreme \u001b[0mCourt \u001b[0mmember. \u001b[0mThe \u001b[0mformer \u001b[0mgovernor \u001b[0mwas \u001b[0malso \u001b[0mone \u001b[0mof \u001b[0mthe \u001b[0marchitects \u001b[0mof \u001b[0mlast \u001b[0mspring's \u001b[0mSuper \u001b[0mTuesday \u001b[0mpresidential \u001b[0mprimary, \u001b[0mintended \u001b[0min \u001b[0mpart \u001b[0mto \u001b[0mgive \u001b[0mthe \u001b[0mSouthern \u001b[0mvote \u001b[0mcollective \u001b[0mstrength. \u001b[0mBut \u001b[0mRobb's \u001b[0mtenure \u001b[0mwas \u001b[0mshaken \u001b[0mby \u001b[0mprison \u001b[0mtroubles \u001b[0mthat \u001b[0mdrew \u001b[0mnational \u001b[0mattention \u001b[0mwhen \u001b[0msix \u001b[0mdeath \u001b[0mrow \u001b[0minmates \u001b[0mescaped \u001b[0min \u001b[0mMay \u001b[0m1984. \u001b[0mRobb, \u001b[0mwho \u001b[0mcould \u001b[0mnot \u001b[0msucceed \u001b[0mhimself \u001b[0munder \u001b[0mVirginia's \u001b[0mconstitution, \u001b[0mhad \u001b[0mbeen \u001b[0mout \u001b[0mof \u001b[0moffice \u001b[0mfor \u001b[0mthree \u001b[0myears \u001b[0mand \u001b[0mpracticing \u001b[0mlaw \u001b[0muntil \u001b[0mhis \u001b[0mbid \u001b[0mfor \u001b[0mthe \u001b[0mSenate. \u001b[0m``I've \u001b[0mbeen \u001b[0munemployed \u001b[0mfor \u001b[0ma \u001b[0mlong \u001b[0mtime, \u001b[0mand \u001b[0mit \u001b[0mlooks \u001b[0mlike \u001b[0mI \u001b[0mjust \u001b[0mgot \u001b[0ma \u001b[0mjob,'' \u001b[0mhe \u001b[0msaid. "
     ]
    }
   ],
   "source": [
    "#http://ozzmaker.com/add-colour-to-text-in-python/\n",
    "#print(\"Examples of how to use ANSI COLOR: \\033[1;37;40m White          \\033[0m 1;37;40m            \\033[0;37;40m Light Grey \\033[0m 0;37;40m               \\033[0;37;48m Black      \\033[0m 0;37;48m\")\n",
    "colors_ansi=[34, 32,31] #blue, green, red\n",
    "             \n",
    "             \n",
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48m\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48m\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REUTERS DATA (get from the external program to keep this a bit tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\bjeli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_max_reuters =  7769\n",
      "We have  100  Documents with sizes:  [633, 259, 119, 155, 115, 34, 250, 83, 182, 133, 126, 85, 84, 111, 99, 101, 67, 26, 73, 140, 108, 173, 49, 236, 109, 111, 365, 42, 66, 49, 130, 90, 52, 21, 136, 14, 28, 102, 110, 67, 72, 143, 196, 31, 24, 34, 601, 32, 123, 958, 193, 118, 36, 55, 54, 113, 36, 67, 569, 25, 100, 185, 60, 145, 78, 61, 10, 87, 252, 61, 151, 466, 128, 44, 25, 179, 180, 54, 167, 42, 76, 114, 301, 506, 78, 83, 51, 111, 254, 10, 136, 186, 127, 145, 85, 34, 34, 91, 68, 77]\n"
     ]
    }
   ],
   "source": [
    "from getReuters import D_reuters as corpus_reuters\n",
    "from getReuters import vocab_list as vocabulary_reuters\n",
    "vocabulary_reuters=np.array(vocabulary_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_reuters = 2\n",
    "corpus_reuters_reduced = corpus_reuters[:10]\n",
    "M_reuters = len(corpus_reuters_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-92813c4c58a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0malpha_init_reuters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_init_reuters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma_init_reuters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_init_reuters\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minitialize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_reuters_reduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary_reuters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_reuters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "alpha_init_reuters, beta_init_reuters, gamma_init_reuters, phi_init_reuters =\\\n",
    "    initialize_parameters(corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_reuters, gamma_reuters, alpha_reuters, Beta_reuters, likelihood_reuters = \\\n",
    "        variational_EM(phi_init_reuters, gamma_init_reuters, alpha_init_reuters, beta_init_reuters, \n",
    "                       corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Analysis for REUTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(Beta_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_LDA_vEM():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
