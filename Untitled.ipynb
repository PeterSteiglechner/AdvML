{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2434_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS:\n",
    "\n",
    "k - number of topics\n",
    "N - number of words in a document (different for each document)\n",
    "M - number of documents in a corpus\n",
    "\n",
    "Model parameters:\n",
    "z_n - [k] dimension vector; topic distribution for word n \n",
    "Theta - [k] dimension vector; mixture weights\n",
    "alpha - [k] dimension vector; prior probability for theta (mixture weights) (alpha > 0)\n",
    "beta - [k x V] dimension matrix; beta_ij = p(w^j = 1 | z^i = 1) \n",
    "                                 probability for a specific word j given a specific topic i\n",
    "D - list of [V x N] dimension matrices, that is M long = [\\mathbf{w}_1, ... \\mathbf{w}_M];\n",
    "                                 where \\mathbf{w} = [w_1,...,w_N] is [V x N] (one document consisting of N words) \n",
    "\n",
    "\n",
    "Variational parameters:\n",
    "Gamma - [k] dimension vector; determines Theta in the Variational Model\n",
    "Phi = phi_1 .. phi_N - [N x k] dimension matrix; determines the probability distribution \n",
    "                                 for topics z of words in the Variational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import special\n",
    "from scipy.special import digamma, gammaln, polygamma\n",
    "import pandas as pd\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Document Corpus\n",
    "Download the data from \n",
    "https://github.com/Blei-Lab/lda-c/blob/master/example/ap.tgz\n",
    "\n",
    "We can directly load the file \"ap.dat\" which contains:\n",
    "\n",
    "1 line = 1 document,\n",
    "\n",
    "[number of different words in doc] [word index (where the one is in w_n]:[how often it occurs in the doc] [word index 2]:[occurences 2] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.genfromtxt('ap/vocab.txt',  dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data(corpus_file, vocabulary_file, stopwords_file):\n",
    "    \"\"\"\n",
    "    Reads the corpus from the .txt file into a list of lists;\n",
    "    a list for each document which contains a list of all the \n",
    "    words as strings.\n",
    "    Input parameters:\n",
    "    corpus_file - path to the corpus file\n",
    "    vocabulary_file - path to the vocabulary file\n",
    "    stopwords_file - path to the stopwords file\n",
    "    \"\"\"\n",
    "    vocabulary = np.genfromtxt(vocabulary_file,  dtype='str')\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "    corpus = []\n",
    "    \n",
    "    # read in stopwords from file into a list\n",
    "    stopwords = [] \n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stop_words = file.read().replace(',', ' ')\n",
    "        for word in stop_words.split():\n",
    "            stopwords.append(word) \n",
    "    \n",
    "    with open(corpus_file, 'r') as text:\n",
    "        doc = ''\n",
    "        new = False\n",
    "        for line in text:\n",
    "            if new: # reached a new document\n",
    "                if line.strip() != '<TEXT>': # until we reach the new doc\n",
    "                    for char in special_chars: # remove punctuation etc,\n",
    "                        line = line.replace(char, '')\n",
    "                    doc += line\n",
    "                else: # we've reached a new doc again\n",
    "                    doc = doc.lower() # all words lowercase\n",
    "                    words = np.array(doc.split())\n",
    "                    doc = [word for word in words if word not in stopwords]\n",
    "                    corpus.append(doc)\n",
    "                    doc = ''\n",
    "            elif line.strip() == '<TEXT>': new = True\n",
    "\n",
    "    \n",
    "    return corpus, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocabulary = clean_up_data('ap/ap.txt', 'ap/vocab.txt', 'ap/stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(documents, vocabulary, k):\n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    # Initialize alpha \n",
    "    # alpha = np.ones([M,k]) * 50/k # for every document, for every topic\n",
    "    alpha = np.ones(k)*50/k\n",
    "    # Initialize beta\n",
    "    beta = np.zeros([k,V]) # for every topic, for every word in the vocabulary\n",
    "    for i in range(k):\n",
    "        beta[i] = np.random.uniform(0, 1, V)\n",
    "        beta[i] = beta[i] / np.sum(beta[i])\n",
    "    \n",
    "    # Initialize phi and gamma\n",
    "    phi = []\n",
    "    gamma = np.zeros([M,k]) # for every document, for every topic\n",
    "    for m in range(M):\n",
    "        doc = np.array(documents[m])\n",
    "        N = len(doc)\n",
    "        phi.append(np.ones([N,k]) * 1/float(k)) # uniform over topics\n",
    "        \n",
    "        for i in range(k):\n",
    "            gamma[m][i] = alpha[i] + N/float(k)\n",
    "        m += 1 # WHYYYYYYY?\n",
    "        \n",
    "    return alpha, beta, gamma, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood(Phi, gamma, alpha, Beta, document, vocabulary, k):\n",
    "    likelihood = 0.0\n",
    "    V = len(vocabulary)\n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "    \n",
    "    alpha_sum = 0.0\n",
    "    phi_gamma_sum = 0.0\n",
    "    phi_logbeta_sum = 0.0\n",
    "    entropy_sum = 0.0\n",
    "    gamma_sum = 0.0\n",
    "    \n",
    "    alpha_sum += gammaln(np.sum(alpha))  \n",
    "    gamma_sum -= gammaln(np.sum(gamma)) \n",
    "    for i in range(k):\n",
    "        alpha_sum += -gammaln(alpha[i]) + \\\n",
    "                (alpha[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "        \n",
    "        for n in range(N):\n",
    "            if Phi[n,i] > 0:\n",
    "                w_indicator = np.sum(np.in1d(vocabulary, words[n]))   \n",
    "                phi_gamma_sum += Phi[n,i] * (digamma(gamma[i]) - digamma(np.sum(gamma[:])))\n",
    "                entropy_sum += Phi[n,i] * np.log(Phi[n,i])\n",
    "                for j in range(V):\n",
    "                    if Beta[i,j] > 0:\n",
    "                        phi_logbeta_sum += Phi[n,i] * w_indicator * np.log(Beta[i,j])\n",
    "            \n",
    "        gamma_sum += gammaln(gamma[i]) - \\\n",
    "                    (gamma[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma[:])))\n",
    "    \n",
    "    likelihood += (alpha_sum + phi_gamma_sum + phi_logbeta_sum - gamma_sum - entropy_sum) \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma(k, phi, gamma, alpha, beta, document, vocabulary, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    security_count = 0\n",
    "    converged = False\n",
    "    \n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (security_count < MAX_STEPS):\n",
    "        security_count += 1\n",
    "            \n",
    "        phi_old = phi\n",
    "        phi = np.zeros([N,k])\n",
    "        gamma_old = gamma\n",
    "            \n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word does not exist in vocabulary\n",
    "                for i in range(k):                \n",
    "                    beta_ = beta[i, np.where(vocabulary == word)]\n",
    "                    phi[n, i] = beta_[0][0] * np.exp(digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "                phi[n,:] = phi[n,:] / np.sum(phi[n,:])   \n",
    "        gamma = alpha + np.sum(phi, axis=0)    \n",
    "            \n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print('Document needed ' + str(security_count) + ' iterations to converge.')\n",
    "                \n",
    "            likelihood += compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k)\n",
    "            converged = True\n",
    "    \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(phi, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = np.zeros([k, V])\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                beta[i][j] += np.dot(indicator, phi_)\n",
    "    beta = np.transpose(np.transpose(beta) / np.sum(beta, axis=1))\n",
    "\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(phi, ni, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    Lambda = np.ones([k, V])*ni\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for n, j in enumerate(words)\n",
    "                Lambda[i][j] += phi_[n]\n",
    "\n",
    "\n",
    "    return Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha, gamma, k, M, max_iter=50, tol=0.0001):\n",
    "    \"\"\"This function updates alpha.\"\"\"\n",
    "    \n",
    "    # Maria B version\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = M * (k * special.polygamma(1, alpha) - special.polygamma(1, k*alpha))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = M * k * (k * special.polygamma(2, k*alpha) - special.polygamma(2, alpha))\n",
    "\n",
    "    temp = gradient / (hessian * alpha + gradient + tol)\n",
    "    if (alpha == 0).any():\n",
    "        alpha += 0.005\n",
    "\n",
    "    log_alpha = np.log(alpha) - temp\n",
    "    alpha = np.exp(log_alpha)    \n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(phi, gamma, alpha, beta, documents, vocabulary, k):\n",
    "\n",
    "    for m, doc in enumerate(documents):\n",
    "        # words = np.array(documents[m])\n",
    "        # N = len(words)\n",
    "        \n",
    "        phi[m], gamma[m], likelihood = update_phi_gamma(k, phi[m], gamma[m], alpha, beta, doc, vocabulary)\n",
    "                \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(phi, gamma, alpha, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    beta = update_beta(phi, documents, vocabulary, k)\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "corpus = corpus[:15]\n",
    "M = len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM(Phi_init, gamma_init, alpha_init, Beta_init, documents, vocabulary, k):\n",
    "    print('Variational EM')\n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    Phi = Phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    Beta = Beta_init\n",
    "    while iteration <= 2 or np.abs((likelihood-likelihood_old)/likelihood_old) > 1e-5:\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        Phi_old = Phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        Beta_old = Beta\n",
    "    \n",
    "        Phi, gamma, likelihood = \\\n",
    "            E_step(Phi_old, gamma_old, alpha_old, Beta_old, documents, vocabulary, k)\n",
    "        alpha, Beta = \\\n",
    "            M_step(Phi, gamma, alpha_old, documents, vocabulary, k)\n",
    "                \n",
    "        iteration += 1\n",
    "        \n",
    "        if iteration > 10:\n",
    "            break\n",
    "        \n",
    "    return Phi, gamma, alpha, Beta, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, beta_init, gamma_init, phi_init = initialize_parameters(corpus, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document needed 46 iterations to converge.\n",
      "Document needed 53 iterations to converge.\n",
      "Document needed 44 iterations to converge.\n",
      "Document needed 44 iterations to converge.\n",
      "Document needed 20 iterations to converge.\n",
      "Document needed 61 iterations to converge.\n",
      "Document needed 38 iterations to converge.\n",
      "Document needed 18 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 29 iterations to converge.\n",
      "Document needed 20 iterations to converge.\n",
      "Document needed 24 iterations to converge.\n",
      "Document needed 35 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 61 iterations to converge.\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, likelihood = E_step(phi_init, gamma_init, alpha_init, beta_init, corpus, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M-step\n"
     ]
    }
   ],
   "source": [
    "alpha, beta = M_step(phi, gamma, alpha_init, corpus, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "Document needed 1 iterations to converge.\n",
      "M-step\n",
      "Document needed 52 iterations to converge.\n",
      "Document needed 49 iterations to converge.\n",
      "Document needed 60 iterations to converge.\n",
      "Document needed 53 iterations to converge.\n",
      "Document needed 27 iterations to converge.\n",
      "Document needed 72 iterations to converge.\n",
      "Document needed 48 iterations to converge.\n",
      "Document needed 29 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 39 iterations to converge.\n",
      "Document needed 30 iterations to converge.\n",
      "Document needed 38 iterations to converge.\n",
      "Document needed 44 iterations to converge.\n",
      "Document needed 18 iterations to converge.\n",
      "Document needed 73 iterations to converge.\n",
      "M-step\n",
      "Document needed 51 iterations to converge.\n",
      "Document needed 26 iterations to converge.\n",
      "Document needed 45 iterations to converge.\n",
      "Document needed 36 iterations to converge.\n",
      "Document needed 39 iterations to converge.\n",
      "Document needed 62 iterations to converge.\n",
      "Document needed 36 iterations to converge.\n",
      "Document needed 42 iterations to converge.\n",
      "Document needed 14 iterations to converge.\n",
      "Document needed 47 iterations to converge.\n",
      "Document needed 37 iterations to converge.\n",
      "Document needed 45 iterations to converge.\n",
      "Document needed 44 iterations to converge.\n",
      "Document needed 22 iterations to converge.\n",
      "Document needed 64 iterations to converge.\n",
      "M-step\n",
      "Document needed 22 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 56 iterations to converge.\n",
      "Document needed 15 iterations to converge.\n",
      "Document needed 26 iterations to converge.\n",
      "Document needed 52 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 49 iterations to converge.\n",
      "Document needed 19 iterations to converge.\n",
      "Document needed 39 iterations to converge.\n",
      "Document needed 23 iterations to converge.\n",
      "Document needed 39 iterations to converge.\n",
      "Document needed 31 iterations to converge.\n",
      "Document needed 20 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "M-step\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 51 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "Document needed 14 iterations to converge.\n",
      "Document needed 59 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 45 iterations to converge.\n",
      "Document needed 20 iterations to converge.\n",
      "Document needed 35 iterations to converge.\n",
      "Document needed 14 iterations to converge.\n",
      "Document needed 31 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 16 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "M-step\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 17 iterations to converge.\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 39 iterations to converge.\n",
      "Document needed 14 iterations to converge.\n",
      "Document needed 22 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 18 iterations to converge.\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 15 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "M-step\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 21 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "Document needed 24 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 11 iterations to converge.\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 12 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "M-step\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 13 iterations to converge.\n",
      "Document needed 10 iterations to converge.\n",
      "Document needed 9 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 14 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "M-step\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 7 iterations to converge.\n",
      "Document needed 6 iterations to converge.\n",
      "Document needed 51 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "M-step\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 4 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 5 iterations to converge.\n",
      "Document needed 8 iterations to converge.\n",
      "Document needed 4 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "Phi, gamma, alpha, Beta, likelihood = \\\n",
    "        variational_EM(phi_init, gamma_init, alpha_init, beta_init, corpus, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14317312, 0.14317312, 0.14317312, 0.14317312])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teacher', 'gun', 'american', 'museum', 'liberace', 'text', 'ap', 'year', 'peres', 'doc']\n",
      "['doc', 'won', 'years', 'first', 'panama', 'month', 'police', 'skins', 'ap', 'noriega']\n",
      "['offer', 'mrs', 'noriega', 'years', 'peres', 'production', 'october', 'year', 'police', 'percent']\n",
      "['last', 'states', 'first', 'shot', 'national', 'president', 'official', 'text', 'doc', 'percent']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = beta[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-10:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
