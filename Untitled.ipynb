{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2434_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS:\n",
    "\n",
    "k - number of topics\n",
    "N - number of words in a document (different for each document)\n",
    "M - number of documents in a corpus\n",
    "\n",
    "Model parameters:\n",
    "z_n - [k] dimension vector; topic distribution for word n \n",
    "Theta - [k] dimension vector; mixture weights\n",
    "alpha - [k] dimension vector; prior probability for theta (mixture weights) (alpha > 0)\n",
    "beta - [k x V] dimension matrix; beta_ij = p(w^j = 1 | z^i = 1) \n",
    "                                 probability for a specific word j given a specific topic i\n",
    "D - list of [V x N] dimension matrices, that is M long = [\\mathbf{w}_1, ... \\mathbf{w}_M];\n",
    "                                 where \\mathbf{w} = [w_1,...,w_N] is [V x N] (one document consisting of N words) \n",
    "\n",
    "\n",
    "Variational parameters:\n",
    "Gamma - [k] dimension vector; determines Theta in the Variational Model\n",
    "Phi = phi_1 .. phi_N - [N x k] dimension matrix; determines the probability distribution \n",
    "                                 for topics z of words in the Variational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import special, misc\n",
    "from scipy.special import digamma, gammaln, polygamma\n",
    "import pandas as pd\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Document Corpus\n",
    "Download the data from \n",
    "https://github.com/Blei-Lab/lda-c/blob/master/example/ap.tgz\n",
    "\n",
    "We can directly load the file \"ap.dat\" which contains:\n",
    "\n",
    "1 line = 1 document,\n",
    "\n",
    "[number of different words in doc] [word index (where the one is in w_n]:[how often it occurs in the doc] [word index 2]:[occurences 2] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.genfromtxt('ap/vocab.txt',  dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data(corpus_file, vocabulary_file, stopwords_file):\n",
    "    \"\"\"\n",
    "    Reads the corpus from the .txt file into a list of lists;\n",
    "    a list for each document which contains a list of all the \n",
    "    words as strings.\n",
    "    Input parameters:\n",
    "    corpus_file - path to the corpus file\n",
    "    vocabulary_file - path to the vocabulary file\n",
    "    stopwords_file - path to the stopwords file\n",
    "    \"\"\"\n",
    "    vocabulary = np.genfromtxt(vocabulary_file,  dtype='str')\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "    corpus = []\n",
    "    \n",
    "    # read in stopwords from file into a list\n",
    "    stopwords = [] \n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stop_words = file.read().replace(',', ' ')\n",
    "        for word in stop_words.split():\n",
    "            stopwords.append(word) \n",
    "    \n",
    "    with open(corpus_file, 'r') as text:\n",
    "        doc = ''\n",
    "        new = False\n",
    "        for line in text:\n",
    "            if new: # reached a new document\n",
    "                if line.strip() != '</TEXT>': # until we reach the new doc\n",
    "                    for char in special_chars: # remove punctuation etc,\n",
    "                        line = line.replace(char, '') \n",
    "                    doc += line\n",
    "                else: # we've reached a new doc again\n",
    "                    doc = doc.lower() # all words lowercase\n",
    "                    words = np.array(doc.split())\n",
    "                    # PETER EDIT: next two lines\n",
    "                    doc = [word for word in words if (  (word not in stopwords) and (word in vocabulary)  )]\n",
    "                    corpus.append(doc)\n",
    "                    doc = ''\n",
    "            elif line.strip() == '<TEXT>': new = True\n",
    "\n",
    "    \n",
    "    return corpus, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocabulary = clean_up_data('ap/ap.txt', 'ap/vocab.txt', 'ap/stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(documents, vocabulary, k):\n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    # Initialize alpha \n",
    "    # alpha = np.ones([M,k]) * 50/k # for every document, for every topic\n",
    "    alpha = np.ones(k)*50/k\n",
    "    eta = 5/k\n",
    "    \n",
    "    Lambda = np.random.rand(k,V) * 0.5 + 0.5\n",
    "    \n",
    "    # Initialize beta\n",
    "    beta = np.zeros([k,V]) # for every topic, for every word in the vocabulary\n",
    "    for i in range(k):\n",
    "        beta[i] = np.random.uniform(0, 1, V)\n",
    "        beta[i] = beta[i] / np.sum(beta[i])\n",
    "    \n",
    "    # Initialize phi and gamma\n",
    "    phi = []\n",
    "    gamma = np.zeros([M,k]) # for every document, for every topic\n",
    "    for m in range(M):\n",
    "        doc = np.array(documents[m])\n",
    "        N = len(doc)\n",
    "        phi.append(np.ones([N,k]) * 1/float(k)) # uniform over topics\n",
    "        \n",
    "        for i in range(k):\n",
    "            gamma[m][i] = alpha[i] + N/float(k)\n",
    "        #m += 1 # WHYYYYYYY?\n",
    "        \n",
    "    return alpha, eta, beta, gamma, phi, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary,k):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    k, V = beta.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        term_knvSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            \n",
    "            v = np.where(vocabulary == document[n])[0][0] # here w_n is not a vector\n",
    "            if beta[i,v] <= 0:\n",
    "                print(\"Error: beta[\"+i,v,\"]<=0\")\n",
    "            #L+= phi[n,i] * np.log(beta[i,v]) \n",
    "            term_knvSum += phi[n,i] * np.log(beta[i,v]) \n",
    "\n",
    "    #print(term0,term_knSum, term_kSum)\n",
    "    L_terms = term0 + term_knSum + term_kSum + term_knvSum\n",
    "    \n",
    "    return L_terms\n",
    "    \n",
    "\n",
    "\n",
    "def psi(gamma_i):\n",
    "    # this is the first derivative (via Taylor approximation) of the log \\Gamma function\n",
    "    # according to Wikipedia this is the \"digamma\" function\n",
    "    return scipy.special.digamma(gamma_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDocumentLikelihood(wd, alpha, eta, gamma, digamma_gamma, phi, digamma_lambda, d):\n",
    "\n",
    "    V, K = digamma_lambda.shape\n",
    "    N = len(wd)\n",
    "    \n",
    "    E_theta_alpha = gammaln(alpha*K) - K * gammaln(alpha) \\\n",
    "                        + (alpha-1) * np.sum(digamma_gamma)\n",
    "    \n",
    "    E_z_theta = np.dot(np.sum(phi[d][:N,:], axis = 0), digamma_gamma)\n",
    "    \n",
    "    E_w_z_beta = np.sum(digamma_lambda[d,:] * phi[d][:N,:])\n",
    "    \n",
    "    E_theta_gamma = gammaln(np.sum(gamma[d,:])) - np.sum(gammaln(gamma[d,:])) \\\n",
    "                    + np.dot(gamma[d,:] - 1, digamma_gamma)\n",
    "\n",
    "    E_z_phi = np.sum(phi[d][:N,:] * np.log(phi[d][:N,:]))\n",
    "    \n",
    "\n",
    "    Likelihood = E_theta_alpha + E_z_theta + E_w_z_beta - E_theta_gamma - E_z_phi\n",
    "    return(Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_smoothed(documents, alpha, eta, gamma, phi, Lambda):\n",
    "    \n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda.T) - digamma(np.sum(Lambda, axis = 1))\n",
    "    likelihood = np.zeros([D,1])\n",
    "    \n",
    "    for d in range(D):\n",
    "        digamma_gamma = digamma(gamma[d,:]) - digamma(np.sum(gamma[d,:]))\n",
    "\n",
    "        N = len(documents[d])\n",
    "        E_theta_alpha = gammaln(alpha*K) - K * gammaln(alpha) \\\n",
    "                            + (alpha-1) * np.sum(digamma_gamma)\n",
    "        E_z_theta = np.dot(np.sum(phi[d][:N,:], axis = 0), digamma_gamma)\n",
    "        E_w_z_beta = np.sum(digamma_lambda[d,:] * phi[d][:N,:])\n",
    "        E_theta_gamma = gammaln(np.sum(gamma[d,:])) - np.sum(gammaln(gamma[d,:])) \\\n",
    "                        + np.dot(gamma[d,:] - 1, digamma_gamma)\n",
    "        E_z_phi = np.sum(phi[d][:N,:] * np.log(phi[d][:N,:]))\n",
    "        \n",
    "        likelihood = E_theta_alpha + E_z_theta + E_w_z_beta - E_theta_gamma - E_z_phi\n",
    "\n",
    "        E_beta_eta = K * (gammaln(eta * V) - V * gammaln(eta)) + (eta - 1) * np.sum(digamma_lambda)\n",
    "        E_beta_lambda = np.sum(gammaln(np.sum(Lambda, axis = 1)) - np.sum(gammaln(Lambda), axis = 1)[np.newaxis,:]) \\\n",
    "                        + np.sum((Lambda - 1) * digamma_lambda.T)\n",
    "    \n",
    "    likelihood = np.sum(likelihood) + E_beta_eta - E_beta_lambda\n",
    "    \n",
    "    return(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def copied(Phi, gamma, alpha, Beta, document, vocabulary, k):\n",
    "#    likelihood = 0.0\n",
    "#    V = len(vocabulary)\n",
    "#    words = np.array(document)\n",
    "#    N = len(words)\n",
    "#    print(N,V,k)\n",
    "#    \n",
    "#    alpha_sum = 0.0\n",
    "#    phi_gamma_sum = 0.0\n",
    "#    phi_logbeta_sum = 0.0\n",
    "#    entropy_sum = 0.0\n",
    "#    gamma_sum = 0.0\n",
    "#    \n",
    "#    alpha_sum += gammaln(np.sum(alpha))  \n",
    "#    gamma_sum -= gammaln(np.sum(gamma)) \n",
    "#    \n",
    "#    for i in range(k):\n",
    "#        alpha_sum += -gammaln(alpha[i]) + \\\n",
    "#                (alpha[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "#        \n",
    "#        for n in range(N):\n",
    "#            if Phi[n,i] > 0:\n",
    "#                w_indicator = np.sum(np.in1d(vocabulary, words[n]))   \n",
    "#                phi_gamma_sum += Phi[n,i] * (digamma(gamma[i]) - digamma(np.sum(gamma[:])))\n",
    "#                entropy_sum += Phi[n,i] * np.log(Phi[n,i])\n",
    "#                for j in range(V):\n",
    "#                    if Beta[i,j] > 0:\n",
    "#                        phi_logbeta_sum += Phi[n,i] * w_indicator * np.log(Beta[i,j])\n",
    "#                        #phi_logbeta_sum+=0\n",
    "#        \n",
    "#        gamma_sum += gammaln(gamma[i]) - \\\n",
    "#                    (gamma[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma[:])))\n",
    "#        \n",
    "#        print(\"i: \")\n",
    "#        print(-gammaln(alpha[i]) + \\\n",
    "#                (alpha[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma))))\n",
    "#        print(gammaln(gamma[i]) - \\\n",
    "#                    (gamma[i] - 1) * (digamma(gamma[i]) - digamma(np.sum(gamma[:]))))\n",
    "#        \n",
    "#    \n",
    "#    likelihood += (alpha_sum + phi_gamma_sum + phi_logbeta_sum - gamma_sum - entropy_sum) \n",
    "#    \n",
    "#    print(alpha_sum, gamma_sum, phi_gamma_sum,entropy_sum)\n",
    "#    print(\"L=\",alpha_sum+phi_gamma_sum-gamma_sum-entropy_sum)\n",
    "#\n",
    "#    print(phi_logbeta_sum)\n",
    "#    return likelihood#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma(k, phi, gamma, alpha, beta, document, vocabulary, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    iterations = 0\n",
    "    converged = False\n",
    "    \n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (iterations < MAX_STEPS):\n",
    "        iterations += 1\n",
    "            \n",
    "        phi_old = phi\n",
    "        phi = np.zeros([N,k])\n",
    "        gamma_old = gamma\n",
    "            \n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                for i in range(k):                \n",
    "                    beta_ = beta[i, np.where(vocabulary == word)]\n",
    "                    phi[n, i] = beta_[0][0] * np.exp(digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "                phi[n,:] = phi[n,:] / np.sum(phi[n,:])   \n",
    "        gamma = alpha + np.sum(phi, axis=0)    \n",
    "            \n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print(str(iterations) + ' iterations to converge.')\n",
    "                \n",
    "            likelihood += compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k)\n",
    "            converged = True\n",
    "    \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma_smoothed(documents, alpha, eta, gamma, phi, Lambda, tol = 1e-4, MAX_STEPS = 100):\n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda.T) - digamma(np.sum(Lambda, axis = 1))\n",
    "    for d in range(D):\n",
    "        likelihood = -1e9\n",
    "        converged = False\n",
    "        iterations = 0\n",
    "        \n",
    "        while(not converged):\n",
    "\n",
    "            iterations += 1\n",
    "            wd = documents[d]\n",
    "            \n",
    "            digamma_gamma = digamma(gamma[d,:]) - digamma(np.sum(gamma[d,:]))\n",
    "            \n",
    "            N = len(documents[d])\n",
    "            \n",
    "            phi[d][:N,:] = digamma_gamma + digamma_lambda[d,:]\n",
    "            phi[d][:N,:] = np.exp(phi[d][:N,:] - misc.logsumexp(phi[d][:N,:], axis = 1)[:,np.newaxis])\n",
    "            \n",
    "            gamma[d,:] = alpha + np.sum(phi[d][:N,:], axis = 0)\n",
    "            \n",
    "            newLikelihood = ComputeDocumentLikelihood(wd, alpha, eta, gamma, digamma_gamma, phi, digamma_lambda, d)\n",
    "            dlikelihood = abs((newLikelihood - likelihood)/likelihood)\n",
    "            likelihood = newLikelihood\n",
    "            \n",
    "            if(dlikelihood < tol).any():\n",
    "                converged = True\n",
    "    \n",
    "    #print gamma\n",
    "    return(phi, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(phi, eta, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    Lambda = np.ones([k, V]) * eta\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int)  \n",
    "                Lambda[i][j] += np.dot(indicator, phi_)\n",
    "                    \n",
    "    return Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(phi, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = np.zeros([k, V])\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                beta[i][j] += np.dot(indicator, phi_)\n",
    "    beta = np.transpose(np.transpose(beta) / np.sum(beta, axis=1))\n",
    "\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha, gamma, k, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "    # Maria B version\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = M * (k * special.polygamma(1, alpha) - special.polygamma(1, k*alpha))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = M * k * (k * special.polygamma(2, k*alpha) - special.polygamma(2, alpha))\n",
    "\n",
    "    temp = gradient / (hessian * alpha + gradient + tol)\n",
    "    if (alpha == 0).any():\n",
    "        alpha += 0.005\n",
    "\n",
    "    log_alpha = np.log(alpha) - temp\n",
    "    alpha = np.exp(log_alpha)    \n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eta(eta, gamma, k, V, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = V * (k * special.polygamma(1, eta) - special.polygamma(1, k*eta))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = V * k * (k * special.polygamma(2, k*eta) - special.polygamma(2, eta))\n",
    "\n",
    "    temp = gradient / (hessian * eta + gradient + tol)\n",
    "    if (eta == 0):\n",
    "        eta += 0.005\n",
    "\n",
    "    log_eta = np.log(eta) - temp\n",
    "    eta = np.exp(log_eta)    \n",
    "        \n",
    "    return eta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(phi, gamma, alpha, beta, documents, vocabulary, k):\n",
    "\n",
    "    for d, doc in enumerate(documents):\n",
    "        phi[d], gamma[d], likelihood = update_phi_gamma(k, phi[d], gamma[d], alpha, beta, doc, vocabulary)\n",
    "                \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step_smoothed(documents, alpha, eta, gamma, phi, Lambda, Tol = 1e-5, MAX_STEPS = 100):\n",
    "\n",
    "    K, V = Lambda.shape\n",
    "    D = len(documents)\n",
    "    \n",
    "    iterations = 0\n",
    "    likelihood = -1e9\n",
    "    converged = False\n",
    "    while(not(converged)):\n",
    "        \n",
    "        iterations += 1\n",
    "        phi, gamma = update_phi_gamma_smoothed(documents, alpha, eta, gamma, phi, Lambda)\n",
    "        Lambda = update_lambda(phi, eta, documents, vocabulary, k)\n",
    "\n",
    "\n",
    "        newLikelihood = compute_likelihood_smoothed(documents, alpha, eta, gamma, phi, Lambda)\n",
    "        dlikelihood = abs((newLikelihood - likelihood)/likelihood)\n",
    "        likelihood = newLikelihood\n",
    "\n",
    "        if(dlikelihood < Tol).any():\n",
    "            print('E-step converged after %d iterations' %iterations)\n",
    "            converged = True\n",
    "    return(phi, gamma, Lambda, likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(phi, gamma, alpha, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    beta = update_beta(phi, documents, vocabulary, k)\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    eta = update_eta(eta, gamma, k, V, M)\n",
    "    print(\"NEW DEBU\")\n",
    "    print(eta)\n",
    "    \n",
    "    return alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM(phi_init, gamma_init, alpha_init, beta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "    \n",
    "        phi, gamma, likelihood = \\\n",
    "            E_step(phi_old, gamma_old, alpha_old, beta_old, documents, vocabulary, k)\n",
    "        alpha, Beta = \\\n",
    "            M_step(phi, gamma, alpha_old, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, alpha, Beta, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    Lambda = Lambda_init\n",
    "    eta = eta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "        Lambda_old = Lambda\n",
    "        eta_old = eta\n",
    "        \n",
    "    \n",
    "        phi, gamma, Lambda, likelihood = \\\n",
    "            E_step_smoothed(documents, alpha_old, eta_old, gamma_old, phi_old, Lambda_old)\n",
    "        alpha, eta = \\\n",
    "            M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, Lambda, alpha, eta, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "corpus_reduced = corpus[:3]\n",
    "M = len(corpus_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "39 iterations to converge.\n",
      "41 iterations to converge.\n",
      "45 iterations to converge.\n",
      "M-step\n",
      "45 iterations to converge.\n",
      "46 iterations to converge.\n",
      "51 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, alpha, beta, likelihood = \\\n",
    "        variational_EM(phi_init, gamma_init, alpha_init, beta_init, corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: smoothed LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjeli\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `logsumexp` is deprecated!\n",
      "Importing `logsumexp` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.logsumexp` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-step converged after 11 iterations\n",
      "M-step\n",
      "NEW DEBU\n",
      "1.0352422730586692\n",
      "E-step converged after 2 iterations\n",
      "M-step\n",
      "NEW DEBU\n",
      "0.6663281132982769\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, Lambda, alpha, eta, likelihood = \\\n",
    "variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, corpus_reduced, vocabulary, k, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1945d1b518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(gamma.T)\n",
    "plt.xlabel(\"Documents\")\n",
    "plt.ylabel(\"topic 1..k\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolormesh(Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['students', 'school', 'bechtel', 'police', 'offer']\n",
      "['man', 'teacher', 'liberace', 'official', 'peres']\n",
      "['museum', 'shot', 'liberace', 'mrs', 'police']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = beta[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-5:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TEXT WITH COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A yearold student at a private Baptist school who allegedly killed one teacher and wounded another before firing into a filled classroom apparently just snapped the schools pastor said I dont know how it could have happened said George Sweet pastor of Atlantic Shores Baptist Church This is a good Christian school We pride ourselves on discipline Our kids are good kids The Atlantic Shores Christian School sophomore was arrested and charged with firstdegree murder attempted murder malicious assault and related felony charges for the Friday morning shooting Police would not release the boys name because he is a juvenile'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_text(corpus_file, number_of_text):\n",
    "    fulltext_words=[]\n",
    "    fulltext_allwords=[]\n",
    "    #number_of_text=2\n",
    "    text_counter=0\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "\n",
    "    with open(corpus_file, 'r') as text:\n",
    "        new=False\n",
    "        for line in text:\n",
    "            if new:\n",
    "                #print(line.strip()[0], line.strip()[:10])\n",
    "                if line.strip()[0]==\"<\":\n",
    "                    pass\n",
    "                else:\n",
    "                    #print(\"FOUND\", text)\n",
    "                    text_counter+=1\n",
    "                    if text_counter==number_of_text:\n",
    "                        #print(\" CORRECT\")\n",
    "                        new_text=line\n",
    "                        fulltext=new_text\n",
    "                        words = np.array(new_text.split())\n",
    "                        for word in words:\n",
    "                            fulltext_allwords.append(word)\n",
    "                            for char in special_chars: # remove punctuation etc,\n",
    "                                word = word.replace(char, '') \n",
    "                            fulltext_words.append(word)\n",
    "\n",
    "\n",
    "            else:\n",
    "                if line.strip() == \"<TEXT>\":\n",
    "                    new=True\n",
    "    return fulltext_words, fulltext_allwords\n",
    "\n",
    "fulltext_words, fulltext_allwords = get_full_text('ap/ap.txt', 1)\n",
    "\" \".join(fulltext_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_colorsForWords(how_significant, fulltext_words, beta, vocabulary, colors=colors):\n",
    "    '''\n",
    "    how_significant=2, tells you the factor that the dominance of one of the beta values for a word over the mean of beta\n",
    "    fulltext_words should be all the relevant words: either fulltext_words, or fulltext_words_reuters\n",
    "    beta.\n",
    "    vocabulary  = vocabulary or vocabulary_reuters\n",
    "    '''\n",
    "    fulltext_colors=[]\n",
    "    #how_significant=2\n",
    "    significance=[]\n",
    "    for word in fulltext_words:\n",
    "        if word in vocabulary:\n",
    "            v = np.where(vocabulary==word)[0][0]\n",
    "            #print(v,word_beta )\n",
    "            word_beta = beta[:,v]\n",
    "            #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "            if np.max(word_beta)>np.mean(beta):\n",
    "                if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                    #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                    topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                    color = colors[topic]\n",
    "                    print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "                else:\n",
    "                    color='k'\n",
    "            else:\n",
    "                color='k'\n",
    "        else: \n",
    "            color='k'\n",
    "        fulltext_colors.append(color)\n",
    "    return fulltext_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastor= 2, pastor= 2, good= 0, kids= 1, good= 0, kids= 1, related= 0, shooting= 0, juvenile= 1, identified= 0, fired= 2, floor= 1, knew= 2, knew= 2, big= 1, identified= 0, third= 2, running= 0, third= 2, spokesman= 1, motive= 1, fired= 2, adult= 2, youngsters= 0, adult= 2, federal= 2, occurred= 2, outside= 2, "
     ]
    }
   ],
   "source": [
    "colors=['blue','green', 'red']\n",
    "\n",
    "fulltext_colors = get_colorsForWords(2, fulltext_words, beta, vocabulary, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mA \u001b[0m16-year-old \u001b[0mstudent \u001b[0mat \u001b[0ma \u001b[0mprivate \u001b[0mBaptist \u001b[0mschool \u001b[0mwho \u001b[0mallegedly \u001b[0mkilled \u001b[0mone \u001b[0mteacher \u001b[0mand \u001b[0mwounded \u001b[0manother \u001b[0mbefore \u001b[0mfiring \u001b[0minto \u001b[0ma \u001b[0mfilled \u001b[0mclassroom \u001b[0mapparently \u001b[0m``just \u001b[0msnapped,'' \u001b[0mthe \u001b[0mschool's \u001b[0;31;48mpastor \u001b[0msaid. \u001b[0m``I \u001b[0mdon't \u001b[0mknow \u001b[0mhow \u001b[0mit \u001b[0mcould \u001b[0mhave \u001b[0mhappened,'' \u001b[0msaid \u001b[0mGeorge \u001b[0mSweet, \u001b[0;31;48mpastor \u001b[0mof \u001b[0mAtlantic \u001b[0mShores \u001b[0mBaptist \u001b[0mChurch. \u001b[0m``This \u001b[0mis \u001b[0ma \u001b[0;34;48mgood, \u001b[0mChristian \u001b[0mschool. \u001b[0mWe \u001b[0mpride \u001b[0mourselves \u001b[0mon \u001b[0mdiscipline. \u001b[0mOur \u001b[0;32;48mkids \u001b[0mare \u001b[0;34;48mgood \u001b[0;32;48mkids.'' \u001b[0mThe \u001b[0mAtlantic \u001b[0mShores \u001b[0mChristian \u001b[0mSchool \u001b[0msophomore \u001b[0mwas \u001b[0marrested \u001b[0mand \u001b[0mcharged \u001b[0mwith \u001b[0mfirst-degree \u001b[0mmurder, \u001b[0mattempted \u001b[0mmurder, \u001b[0mmalicious \u001b[0massault \u001b[0mand \u001b[0;34;48mrelated \u001b[0mfelony \u001b[0mcharges \u001b[0mfor \u001b[0mthe \u001b[0mFriday \u001b[0mmorning \u001b[0;34;48mshooting. \u001b[0mPolice \u001b[0mwould \u001b[0mnot \u001b[0mrelease \u001b[0mthe \u001b[0mboy's \u001b[0mname \u001b[0mbecause \u001b[0mhe \u001b[0mis \u001b[0ma \u001b[0;32;48mjuvenile, \u001b[0mbut \u001b[0mneighbors \u001b[0mand \u001b[0mrelatives \u001b[0;34;48midentified \u001b[0mhim \u001b[0mas \u001b[0mNicholas \u001b[0mElliott. \u001b[0mPolice \u001b[0msaid \u001b[0mthe \u001b[0mstudent \u001b[0mwas \u001b[0mtackled \u001b[0mby \u001b[0ma \u001b[0mteacher \u001b[0mand \u001b[0mother \u001b[0mstudents \u001b[0mwhen \u001b[0mhis \u001b[0msemiautomatic \u001b[0mpistol \u001b[0mjammed \u001b[0mas \u001b[0mhe \u001b[0;31;48mfired \u001b[0mon \u001b[0mthe \u001b[0mclassroom \u001b[0mas \u001b[0mthe \u001b[0mstudents \u001b[0mcowered \u001b[0mon \u001b[0mthe \u001b[0;32;48mfloor \u001b[0mcrying \u001b[0m``Jesus \u001b[0msave \u001b[0mus! \u001b[0mGod \u001b[0msave \u001b[0mus!'' \u001b[0mFriends \u001b[0mand \u001b[0mfamily \u001b[0msaid \u001b[0mthe \u001b[0mboy \u001b[0mapparently \u001b[0mwas \u001b[0mtroubled \u001b[0mby \u001b[0mhis \u001b[0mgrandmother's \u001b[0mdeath \u001b[0mand \u001b[0mthe \u001b[0mdivorce \u001b[0mof \u001b[0mhis \u001b[0mparents \u001b[0mand \u001b[0mhad \u001b[0mbeen \u001b[0mtormented \u001b[0mby \u001b[0mclassmates. \u001b[0mNicholas' \u001b[0mgrandfather, \u001b[0mClarence \u001b[0mElliott \u001b[0mSr., \u001b[0msaid \u001b[0mSaturday \u001b[0mthat \u001b[0mthe \u001b[0mboy's \u001b[0mparents \u001b[0mseparated \u001b[0mabout \u001b[0mfour \u001b[0myears \u001b[0mago \u001b[0mand \u001b[0mhis \u001b[0mmaternal \u001b[0mgrandmother, \u001b[0mChanney \u001b[0mWilliams, \u001b[0mdied \u001b[0mlast \u001b[0myear \u001b[0mafter \u001b[0ma \u001b[0mlong \u001b[0millness. \u001b[0mThe \u001b[0mgrandfather \u001b[0malso \u001b[0msaid \u001b[0mhis \u001b[0mgrandson \u001b[0mwas \u001b[0mfascinated \u001b[0mwith \u001b[0mguns. \u001b[0m``The \u001b[0mboy \u001b[0mwas \u001b[0malways \u001b[0mtalking \u001b[0mabout \u001b[0mguns,'' \u001b[0mhe \u001b[0msaid. \u001b[0m``He \u001b[0;31;48mknew \u001b[0ma \u001b[0mlot \u001b[0mabout \u001b[0mthem. \u001b[0mHe \u001b[0;31;48mknew \u001b[0mall \u001b[0mthe \u001b[0mnames \u001b[0mof \u001b[0mthem \u001b[0m_ \u001b[0mnone \u001b[0mof \u001b[0mthose \u001b[0mlittle \u001b[0mguns \u001b[0mlike \u001b[0ma \u001b[0m.32 \u001b[0mor \u001b[0ma \u001b[0m.22 \u001b[0mor \u001b[0mnothing \u001b[0mlike \u001b[0mthat. \u001b[0mHe \u001b[0mliked \u001b[0mthe \u001b[0;32;48mbig \u001b[0mones.'' \u001b[0mThe \u001b[0mslain \u001b[0mteacher \u001b[0mwas \u001b[0;34;48midentified \u001b[0mas \u001b[0mKaren \u001b[0mH. \u001b[0mFarley, \u001b[0m40. \u001b[0mThe \u001b[0mwounded \u001b[0mteacher, \u001b[0m37-year-old \u001b[0mSam \u001b[0mMarino, \u001b[0mwas \u001b[0min \u001b[0mserious \u001b[0mcondition \u001b[0mSaturday \u001b[0mwith \u001b[0mgunshot \u001b[0mwounds \u001b[0min \u001b[0mthe \u001b[0mshoulder. \u001b[0mPolice \u001b[0msaid \u001b[0mthe \u001b[0mboy \u001b[0malso \u001b[0mshot \u001b[0mat \u001b[0ma \u001b[0;31;48mthird \u001b[0mteacher, \u001b[0mSusan \u001b[0mAllen, \u001b[0m31, \u001b[0mas \u001b[0mshe \u001b[0mfled \u001b[0mfrom \u001b[0mthe \u001b[0mroom \u001b[0mwhere \u001b[0mMarino \u001b[0mwas \u001b[0mshot. \u001b[0mHe \u001b[0mthen \u001b[0mshot \u001b[0mMarino \u001b[0magain \u001b[0mbefore \u001b[0;34;48mrunning \u001b[0mto \u001b[0ma \u001b[0;31;48mthird \u001b[0mclassroom \u001b[0mwhere \u001b[0ma \u001b[0mBible \u001b[0mclass \u001b[0mwas \u001b[0mmeeting. \u001b[0mThe \u001b[0myoungster \u001b[0mshot \u001b[0mthe \u001b[0mglass \u001b[0mout \u001b[0mof \u001b[0ma \u001b[0mlocked \u001b[0mdoor \u001b[0mbefore \u001b[0mopening \u001b[0mfire, \u001b[0mpolice \u001b[0;32;48mspokesman \u001b[0mLewis \u001b[0mThurston \u001b[0msaid. \u001b[0mWhen \u001b[0mthe \u001b[0myouth's \u001b[0mpistol \u001b[0mjammed, \u001b[0mhe \u001b[0mwas \u001b[0mtackled \u001b[0mby \u001b[0mteacher \u001b[0mMaurice \u001b[0mMatteson, \u001b[0m24, \u001b[0mand \u001b[0mother \u001b[0mstudents, \u001b[0mThurston \u001b[0msaid. \u001b[0m``Once \u001b[0myou \u001b[0msee \u001b[0mwhat \u001b[0mwent \u001b[0mon \u001b[0min \u001b[0mthere, \u001b[0mit's \u001b[0ma \u001b[0mmiracle \u001b[0mthat \u001b[0mwe \u001b[0mdidn't \u001b[0mhave \u001b[0mmore \u001b[0mpeople \u001b[0mkilled,'' \u001b[0mPolice \u001b[0mChief \u001b[0mCharles \u001b[0mR. \u001b[0mWall \u001b[0msaid. \u001b[0mPolice \u001b[0mdidn't \u001b[0mhave \u001b[0ma \u001b[0;32;48mmotive, \u001b[0mDetective \u001b[0mTom \u001b[0mZucaro \u001b[0msaid, \u001b[0mbut \u001b[0mbelieve \u001b[0mthe \u001b[0mboy's \u001b[0mprimary \u001b[0mtarget \u001b[0mwas \u001b[0mnot \u001b[0ma \u001b[0mteacher \u001b[0mbut \u001b[0ma \u001b[0mclassmate. \u001b[0mOfficers \u001b[0mfound \u001b[0mwhat \u001b[0mappeared \u001b[0mto \u001b[0mbe \u001b[0mthree \u001b[0mMolotov \u001b[0mcocktails \u001b[0min \u001b[0mthe \u001b[0mboy's \u001b[0mlocker \u001b[0mand \u001b[0mconfiscated \u001b[0mthe \u001b[0mgun \u001b[0mand \u001b[0mseveral \u001b[0mspent \u001b[0mshell \u001b[0mcasings. \u001b[0mFourteen \u001b[0mrounds \u001b[0mwere \u001b[0;31;48mfired \u001b[0mbefore \u001b[0mthe \u001b[0mgun \u001b[0mjammed, \u001b[0mThurston \u001b[0msaid. \u001b[0mThe \u001b[0mgun, \u001b[0mwhich \u001b[0mthe \u001b[0mboy \u001b[0mcarried \u001b[0mto \u001b[0mschool \u001b[0min \u001b[0mhis \u001b[0mknapsack, \u001b[0mwas \u001b[0mpurchased \u001b[0mby \u001b[0man \u001b[0;31;48madult \u001b[0mat \u001b[0mthe \u001b[0;34;48myoungster's \u001b[0mrequest, \u001b[0mThurston \u001b[0msaid, \u001b[0madding \u001b[0mthat \u001b[0mauthorities \u001b[0mhave \u001b[0minterviewed \u001b[0mthe \u001b[0;31;48madult, \u001b[0mwhose \u001b[0mname \u001b[0mis \u001b[0mbeing \u001b[0mwithheld \u001b[0mpending \u001b[0man \u001b[0minvestigation \u001b[0mby \u001b[0mthe \u001b[0;31;48mfederal \u001b[0mBureau \u001b[0mof \u001b[0mAlcohol, \u001b[0mTobacco \u001b[0mand \u001b[0mFirearms. \u001b[0mThe \u001b[0mshootings \u001b[0;31;48moccurred \u001b[0min \u001b[0ma \u001b[0mcomplex \u001b[0mof \u001b[0mfour \u001b[0mportable \u001b[0mclassrooms \u001b[0mfor \u001b[0mjunior \u001b[0mand \u001b[0msenior \u001b[0mhigh \u001b[0mschool \u001b[0mstudents \u001b[0;31;48moutside \u001b[0mthe \u001b[0mmain \u001b[0mbuilding \u001b[0mof \u001b[0mthe \u001b[0m4-year-old \u001b[0mschool. \u001b[0mThe \u001b[0mschool \u001b[0mhas \u001b[0m500 \u001b[0mstudents \u001b[0min \u001b[0mkindergarten \u001b[0mthrough \u001b[0m12th \u001b[0mgrade. \u001b[0mPolice \u001b[0msaid \u001b[0mthey \u001b[0mwere \u001b[0mtrying \u001b[0mto \u001b[0mreconstruct \u001b[0mthe \u001b[0msequence \u001b[0mof \u001b[0mevents \u001b[0mand \u001b[0mhad \u001b[0mnot \u001b[0mresolved \u001b[0mwho \u001b[0mwas \u001b[0mshot \u001b[0mfirst. \u001b[0mThe \u001b[0mbody \u001b[0mof \u001b[0mMs. \u001b[0mFarley \u001b[0mwas \u001b[0mfound \u001b[0mabout \u001b[0man \u001b[0mhour \u001b[0mafter \u001b[0mthe \u001b[0mshootings \u001b[0mbehind \u001b[0ma \u001b[0mclassroom \u001b[0mdoor. "
     ]
    }
   ],
   "source": [
    "\n",
    "def write_colored_text(fulltext_allwords, fulltext_colors, colors=colors):\n",
    "    #http://ozzmaker.com/add-colour-to-text-in-python/\n",
    "    #print(\"Examples of how to use ANSI COLOR: \\033[1;37;40m White          \\033[0m 1;37;40m            \\033[0;37;40m Light Grey \\033[0m 0;37;40m               \\033[0;37;48m Black      \\033[0m 0;37;48m\")\n",
    "    colors_ansi=[34, 32,31] #blue, green, red\n",
    "\n",
    "    for a in range(len(fulltext_allwords)):\n",
    "        if fulltext_colors[a]=='k':\n",
    "            #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "            #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "            print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "\n",
    "            #print(fulltext_allwords[a], end=\" \")\n",
    "        else:\n",
    "            for j in range(k):\n",
    "                 if fulltext_colors[a]==colors[j]:\n",
    "                    print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")\n",
    "    return\n",
    "                \n",
    "                \n",
    "write_colored_text(fulltext_allwords, fulltext_colors, colors=colors)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48mgood, good, related, shooting, identified, identified, running, youngsters\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48mkids, kids, juvenile, floor, big, spokesman, motive\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48mpastor, pastor, fired, knew, knew, third, third, fired, adult, adult, federal, occurred, outside\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REUTERS DATA (get from the external program to keep this a bit tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/peter/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_max_reuters =  7769\n",
      "We have  100  Documents with sizes:  [633, 259, 119, 155, 115, 34, 250, 83, 182, 133, 126, 85, 84, 111, 99, 101, 67, 26, 73, 140, 108, 173, 49, 236, 109, 111, 365, 42, 66, 49, 130, 90, 52, 21, 136, 14, 28, 102, 110, 67, 72, 143, 196, 31, 24, 34, 601, 32, 123, 958, 193, 118, 36, 55, 54, 113, 36, 67, 569, 25, 100, 185, 60, 145, 78, 61, 10, 87, 252, 61, 151, 466, 128, 44, 25, 179, 180, 54, 167, 42, 76, 114, 301, 506, 78, 83, 51, 111, 254, 10, 136, 186, 127, 145, 85, 34, 34, 91, 68, 77]\n"
     ]
    }
   ],
   "source": [
    "from getReuters import D_reuters as corpus_reuters\n",
    "from getReuters import vocab_list as vocabulary_reuters\n",
    "vocabulary_reuters=np.array(vocabulary_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_reuters = 2\n",
    "corpus_reuters_reduced = corpus_reuters[:5]\n",
    "M_reuters = len(corpus_reuters_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init_reuters, eta_reuters_init, beta_init_reuters, gamma_init_reuters, phi_init_reuters, lambdabda_init_reuters = \\\n",
    "    initialize_parameters(corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "31 iterations to converge.\n",
      "25 iterations to converge.\n",
      "15 iterations to converge.\n",
      "20 iterations to converge.\n",
      "18 iterations to converge.\n",
      "M-step\n",
      "32 iterations to converge.\n",
      "30 iterations to converge.\n",
      "19 iterations to converge.\n",
      "24 iterations to converge.\n",
      "22 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "Phi_reuters, gamma_reuters, alpha_reuters, Beta_reuters, likelihood_reuters = \\\n",
    "        variational_EM(phi_init_reuters, gamma_init_reuters, alpha_init_reuters, beta_init_reuters, \n",
    "                       corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Analysis for REUTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f193d13ae10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(Beta_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getReuters import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bahia cocoa review showers continued throughout the week in the bahia cocoa zone , alleviating the drought since early january and improving prospects for the coming temporao , although normal humidity levels have not been restored , comissaria smith said in its weekly review . the dry period means the temporao will be late this year . arrivals for the week ended february 22 were 155 , 221 bags of 60 kilos making a cumulative total for the season of 5 . 93 mln against 5 . 81 at the same stage last year . again it seems that cocoa'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_text_reuters(number_of_text):\n",
    "    fulltext = \" \".join(training[number_of_text-1]).lower().split()\n",
    "    fulltext_words=[]\n",
    "    fulltext_allwords=[]\n",
    "        \n",
    "    for w in fulltext:\n",
    "        \n",
    "        if w in vocabulary_reuters:\n",
    "            fulltext_words.append(w)\n",
    "\n",
    "        fulltext_allwords.append(w)\n",
    "        \n",
    "    return fulltext_words,fulltext_allwords\n",
    "\n",
    "fulltext_words_reuters, fulltext_allwords_reuters = get_full_text_reuters(1)\n",
    "\" \".join(fulltext_allwords_reuters[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throughout= 1, week= 0, alleviating= 1, early= 0, prospects= 1, week= 0, cumulative= 0, season= 1, mln= 0, harvesting= 1, mln= 0, mln= 0, fit= 1, quality= 1, part= 1, bean= 0, bean= 0, dlrs= 1, ports= 1, named= 1, ports= 1, dlrs= 1, dlrs= 1, dlrs= 1, butter= 1, made= 1, dlrs= 1, butter= 1, dlrs= 1, dlrs= 1, dec= 1, dlrs= 1, dec= 1, ports= 1, dlrs= 1, dlrs= 1, dlrs= 1, dec= 1, dec= 1, dlrs= 1, dlrs= 1, dlrs= 1, dec= 1, dec= 1, mln= 0, mln= 0, final= 1, expected= 1, trade= 0, "
     ]
    }
   ],
   "source": [
    "colors=['blue','green', 'red']\n",
    "\n",
    "\n",
    "fulltext_colors_reuters = get_colorsForWords(1.8, fulltext_words_reuters, Beta_reuters, vocabulary_reuters, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mbahia \u001b[0mcocoa \u001b[0mreview \u001b[0mshowers \u001b[0mcontinued \u001b[0;32;48mthroughout \u001b[0mthe \u001b[0;34;48mweek \u001b[0min \u001b[0mthe \u001b[0mbahia \u001b[0mcocoa \u001b[0mzone \u001b[0;32;48m, \u001b[0malleviating \u001b[0mthe \u001b[0mdrought \u001b[0;34;48msince \u001b[0mearly \u001b[0mjanuary \u001b[0mand \u001b[0;32;48mimproving \u001b[0mprospects \u001b[0mfor \u001b[0mthe \u001b[0mcoming \u001b[0mtemporao \u001b[0m, \u001b[0malthough \u001b[0mnormal \u001b[0mhumidity \u001b[0mlevels \u001b[0mhave \u001b[0mnot \u001b[0mbeen \u001b[0mrestored \u001b[0m, \u001b[0mcomissaria \u001b[0msmith \u001b[0msaid \u001b[0min \u001b[0mits \u001b[0mweekly \u001b[0mreview \u001b[0m. \u001b[0mthe \u001b[0mdry \u001b[0mperiod \u001b[0mmeans \u001b[0mthe \u001b[0mtemporao \u001b[0mwill \u001b[0;34;48mbe \u001b[0mlate \u001b[0mthis \u001b[0myear \u001b[0m. \u001b[0marrivals \u001b[0mfor \u001b[0mthe \u001b[0;34;48mweek \u001b[0mended \u001b[0mfebruary \u001b[0m22 \u001b[0;32;48mwere \u001b[0m155 \u001b[0;34;48m, \u001b[0m221 \u001b[0mbags \u001b[0mof \u001b[0m60 \u001b[0mkilos \u001b[0mmaking \u001b[0ma \u001b[0mcumulative \u001b[0mtotal \u001b[0mfor \u001b[0mthe \u001b[0mseason \u001b[0mof \u001b[0m5 \u001b[0m. \u001b[0m93 \u001b[0mmln \u001b[0magainst \u001b[0m5 \u001b[0m. \u001b[0m81 \u001b[0mat \u001b[0mthe \u001b[0msame \u001b[0mstage \u001b[0mlast \u001b[0myear \u001b[0m. \u001b[0magain \u001b[0mit \u001b[0mseems \u001b[0mthat \u001b[0mcocoa \u001b[0mdelivered \u001b[0mearlier \u001b[0mon \u001b[0;32;48mconsignment \u001b[0mwas \u001b[0mincluded \u001b[0min \u001b[0mthe \u001b[0marrivals \u001b[0mfigures \u001b[0m. \u001b[0mcomissaria \u001b[0msmith \u001b[0msaid \u001b[0mthere \u001b[0;34;48mis \u001b[0mstill \u001b[0msome \u001b[0mdoubt \u001b[0mas \u001b[0mto \u001b[0mhow \u001b[0;34;48mmuch \u001b[0mold \u001b[0mcrop \u001b[0mcocoa \u001b[0mis \u001b[0mstill \u001b[0mavailable \u001b[0mas \u001b[0mharvesting \u001b[0mhas \u001b[0mpractically \u001b[0mcome \u001b[0mto \u001b[0man \u001b[0mend \u001b[0m. \u001b[0mwith \u001b[0mtotal \u001b[0mbahia \u001b[0mcrop \u001b[0mestimates \u001b[0maround \u001b[0m6 \u001b[0m. \u001b[0m4 \u001b[0;32;48mmln \u001b[0mbags \u001b[0mand \u001b[0msales \u001b[0mstanding \u001b[0mat \u001b[0malmost \u001b[0m6 \u001b[0m. \u001b[0m2 \u001b[0mmln \u001b[0mthere \u001b[0mare \u001b[0ma \u001b[0mfew \u001b[0mhundred \u001b[0;32;48mthousand \u001b[0mbags \u001b[0mstill \u001b[0min \u001b[0mthe \u001b[0mhands \u001b[0mof \u001b[0;32;48mfarmers \u001b[0m, \u001b[0mmiddlemen \u001b[0m, \u001b[0mexporters \u001b[0mand \u001b[0mprocessors \u001b[0m. \u001b[0mthere \u001b[0mare \u001b[0;34;48mdoubts \u001b[0mas \u001b[0mto \u001b[0mhow \u001b[0mmuch \u001b[0mof \u001b[0mthis \u001b[0mcocoa \u001b[0mwould \u001b[0mbe \u001b[0;34;48mfit \u001b[0mfor \u001b[0mexport \u001b[0mas \u001b[0mshippers \u001b[0mare \u001b[0mnow \u001b[0mexperiencing \u001b[0mdificulties \u001b[0min \u001b[0mobtaining \u001b[0m+ \u001b[0mbahia \u001b[0msuperior \u001b[0m+ \u001b[0mcertificates \u001b[0;32;48m. \u001b[0min \u001b[0mview \u001b[0mof \u001b[0;32;48mthe \u001b[0mlower \u001b[0mquality \u001b[0;32;48mover \u001b[0mrecent \u001b[0mweeks \u001b[0mfarmers \u001b[0mhave \u001b[0msold \u001b[0ma \u001b[0mgood \u001b[0mpart \u001b[0;32;48mof \u001b[0mtheir \u001b[0mcocoa \u001b[0mheld \u001b[0mon \u001b[0mconsignment \u001b[0m. \u001b[0;32;48mcomissaria \u001b[0msmith \u001b[0msaid \u001b[0mspot \u001b[0;32;48mbean \u001b[0mprices \u001b[0mrose \u001b[0mto \u001b[0m340 \u001b[0mto \u001b[0m350 \u001b[0mcruzados \u001b[0mper \u001b[0;32;48marroba \u001b[0mof \u001b[0m15 \u001b[0mkilos \u001b[0m. \u001b[0mbean \u001b[0mshippers \u001b[0;32;48mwere \u001b[0;32;48mreluctant \u001b[0mto \u001b[0moffer \u001b[0mnearby \u001b[0mshipment \u001b[0mand \u001b[0;32;48monly \u001b[0mlimited \u001b[0msales \u001b[0;32;48mwere \u001b[0mbooked \u001b[0mfor \u001b[0mmarch \u001b[0mshipment \u001b[0mat \u001b[0m1 \u001b[0m, \u001b[0m750 \u001b[0mto \u001b[0m1 \u001b[0;32;48m, \u001b[0m780 \u001b[0mdlrs \u001b[0mper \u001b[0mtonne \u001b[0;32;48mto \u001b[0mports \u001b[0mto \u001b[0mbe \u001b[0mnamed \u001b[0m. \u001b[0mnew \u001b[0mcrop \u001b[0msales \u001b[0mwere \u001b[0;32;48malso \u001b[0mlight \u001b[0;32;48mand \u001b[0mall \u001b[0mto \u001b[0mopen \u001b[0mports \u001b[0;32;48mwith \u001b[0mjune \u001b[0m/ \u001b[0mjuly \u001b[0mgoing \u001b[0mat \u001b[0m1 \u001b[0m, \u001b[0m850 \u001b[0mand \u001b[0m1 \u001b[0m, \u001b[0m880 \u001b[0mdlrs \u001b[0;32;48mand \u001b[0mat \u001b[0m35 \u001b[0mand \u001b[0m45 \u001b[0mdlrs \u001b[0;32;48munder \u001b[0mnew \u001b[0myork \u001b[0mjuly \u001b[0;32;48m, \u001b[0maug \u001b[0m/ \u001b[0;32;48msept \u001b[0mat \u001b[0m1 \u001b[0m, \u001b[0m870 \u001b[0m, \u001b[0m1 \u001b[0;32;48m, \u001b[0m875 \u001b[0mand \u001b[0;32;48m1 \u001b[0m, \u001b[0m880 \u001b[0mdlrs \u001b[0mper \u001b[0mtonne \u001b[0mfob \u001b[0m. \u001b[0mroutine \u001b[0msales \u001b[0mof \u001b[0mbutter \u001b[0mwere \u001b[0mmade \u001b[0m. \u001b[0mmarch \u001b[0m/ \u001b[0mapril \u001b[0msold \u001b[0mat \u001b[0;32;48m4 \u001b[0m, \u001b[0m340 \u001b[0m, \u001b[0;32;48m4 \u001b[0m, \u001b[0m345 \u001b[0mand \u001b[0m4 \u001b[0m, \u001b[0m350 \u001b[0mdlrs \u001b[0m. \u001b[0mapril \u001b[0;32;48m/ \u001b[0mmay \u001b[0mbutter \u001b[0mwent \u001b[0mat \u001b[0m2 \u001b[0m. \u001b[0m27 \u001b[0mtimes \u001b[0;32;48mnew \u001b[0myork \u001b[0mmay \u001b[0m, \u001b[0mjune \u001b[0;32;48m/ \u001b[0mjuly \u001b[0mat \u001b[0m4 \u001b[0m, \u001b[0m400 \u001b[0mand \u001b[0m4 \u001b[0m, \u001b[0m415 \u001b[0;34;48mdlrs \u001b[0m, \u001b[0maug \u001b[0m/ \u001b[0msept \u001b[0mat \u001b[0;34;48m4 \u001b[0m, \u001b[0m351 \u001b[0mto \u001b[0m4 \u001b[0;32;48m, \u001b[0m450 \u001b[0mdlrs \u001b[0mand \u001b[0mat \u001b[0m2 \u001b[0m. \u001b[0;32;48m27 \u001b[0mand \u001b[0m2 \u001b[0m. \u001b[0m28 \u001b[0mtimes \u001b[0mnew \u001b[0myork \u001b[0;34;48msept \u001b[0mand \u001b[0moct \u001b[0m/ \u001b[0mdec \u001b[0mat \u001b[0m4 \u001b[0m, "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-d41059adc155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_colored_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltext_allwords_reuters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfulltext_colors_reuters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtopic_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltext_colors_reuters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\033[0mTOPIC: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\": \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\033[0;\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors_ansi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";48m\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltext_words_reuters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-b07f3ad5ae88>\u001b[0m in \u001b[0;36mwrite_colored_text\u001b[0;34m(fulltext_allwords, fulltext_colors, colors)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltext_allwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfulltext_colors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;31m#IF WE WANT TO FOCUS ON THE TOPIC WORDS:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "       \n",
    "write_colored_text(fulltext_allwords_reuters, fulltext_colors_reuters, colors=colors)\n",
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors_reuters)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words_reuters)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_LDA_vEM():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
