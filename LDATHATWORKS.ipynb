{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2434_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PARAMETERS:\n",
    "\n",
    "k - number of topics\n",
    "N - number of words in a document (different for each document)\n",
    "M - number of documents in a corpus\n",
    "\n",
    "Model parameters:\n",
    "z_n - [k] dimension vector; topic distribution for word n \n",
    "Theta - [k] dimension vector; mixture weights\n",
    "alpha - [k] dimension vector; prior probability for theta (mixture weights) (alpha > 0)\n",
    "beta - [k x V] dimension matrix; beta_ij = p(w^j = 1 | z^i = 1) \n",
    "                                 probability for a specific word j given a specific topic i\n",
    "D - list of [V x N] dimension matrices, that is M long = [\\mathbf{w}_1, ... \\mathbf{w}_M];\n",
    "                                 where \\mathbf{w} = [w_1,...,w_N] is [V x N] (one document consisting of N words) \n",
    "\n",
    "\n",
    "Variational parameters:\n",
    "Gamma - [k] dimension vector; determines Theta in the Variational Model\n",
    "Phi = phi_1 .. phi_N - [N x k] dimension matrix; determines the probability distribution \n",
    "                                 for topics z of words in the Variational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import special, misc\n",
    "from scipy.special import logsumexp\n",
    "from scipy.special import digamma, gammaln, polygamma\n",
    "import pandas as pd\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Document Corpus\n",
    "Download the data from \n",
    "https://github.com/Blei-Lab/lda-c/blob/master/example/ap.tgz\n",
    "\n",
    "We can directly load the file \"ap.dat\" which contains:\n",
    "\n",
    "1 line = 1 document,\n",
    "\n",
    "[number of different words in doc] [word index (where the one is in w_n]:[how often it occurs in the doc] [word index 2]:[occurences 2] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.genfromtxt('ap/vocab.txt',  dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data(corpus_file, vocabulary_file, stopwords_file):\n",
    "    \"\"\"\n",
    "    Reads the corpus from the .txt file into a list of lists;\n",
    "    a list for each document which contains a list of all the \n",
    "    words as strings.\n",
    "    Input parameters:\n",
    "    corpus_file - path to the corpus file\n",
    "    vocabulary_file - path to the vocabulary file\n",
    "    stopwords_file - path to the stopwords file\n",
    "    \"\"\"\n",
    "    vocabulary = np.genfromtxt(vocabulary_file,  dtype='str')\n",
    "    special_chars = '1234567890~!@#£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "    corpus = []\n",
    "    \n",
    "    # read in stopwords from file into a list\n",
    "    stopwords = [] \n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stop_words = file.read().replace(',', ' ')\n",
    "        for word in stop_words.split():\n",
    "            stopwords.append(word) \n",
    "    \n",
    "    with open(corpus_file, 'r') as text:\n",
    "        doc = ''\n",
    "        new = False\n",
    "        for line in text:\n",
    "            if new: # reached a new document\n",
    "                if line.strip() != '</TEXT>': # until we reach the new doc\n",
    "                    for char in special_chars: # remove punctuation etc,\n",
    "                        line = line.replace(char, '') \n",
    "                    doc += line\n",
    "                else: # we've reached a new doc again\n",
    "                    doc = doc.lower() # all words lowercase\n",
    "                    words = np.array(doc.split())\n",
    "                    # PETER EDIT: next two lines\n",
    "                    doc = [word for word in words if (  (word not in stopwords) and (word in vocabulary)  )]\n",
    "                    corpus.append(doc)\n",
    "                    doc = ''\n",
    "            elif line.strip() == '<TEXT>': new = True\n",
    "\n",
    "    \n",
    "    return corpus, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocabulary = clean_up_data('ap/ap.txt', 'ap/vocab.txt', 'ap/stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(documents, vocabulary, k):\n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    # Initialize alpha \n",
    "    # alpha = np.ones([M,k]) * 50/k # for every document, for every topic\n",
    "    alpha = np.ones(k)*50/k\n",
    "    eta = 5/k\n",
    "    \n",
    "    Lambda = np.random.rand(k,V) * 0.5 + 0.5\n",
    "    \n",
    "    # Initialize beta\n",
    "    beta = np.zeros([k,V]) # for every topic, for every word in the vocabulary\n",
    "    for i in range(k):\n",
    "        beta[i] = np.random.uniform(0, 1, V)\n",
    "        beta[i] = beta[i] / np.sum(beta[i])\n",
    "    \n",
    "    # Initialize phi and gamma\n",
    "    phi = []\n",
    "    gamma = np.zeros([M,k]) # for every document, for every topic\n",
    "    for m in range(M):\n",
    "        doc = np.array(documents[m])\n",
    "        N = len(doc)\n",
    "        phi.append(np.ones([N,k]) * 1/float(k)) # uniform over topics\n",
    "        \n",
    "        for i in range(k):\n",
    "            gamma[m][i] = alpha[i] + N/float(k)\n",
    "        #m += 1 # WHYYYYYYY?\n",
    "        \n",
    "    return alpha, eta, beta, gamma, phi, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    k, V = beta.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        term_knvSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            \n",
    "            v = np.where(vocabulary == document[n])[0][0] # here w_n is not a vector\n",
    "            if beta[i,v] <= 0:\n",
    "                print(\"Error: beta[\"+i,v,\"]<=0\")\n",
    "            #L+= phi[n,i] * np.log(beta[i,v]) \n",
    "            term_knvSum += phi[n,i] * np.log(beta[i,v]) \n",
    "\n",
    "    #print(term0,term_knSum, term_kSum)\n",
    "    L_terms = term0 + term_knSum + term_kSum + term_knvSum\n",
    "    \n",
    "    return L_terms\n",
    "    \n",
    "\n",
    "\n",
    "def psi(gamma_i):\n",
    "    # this is the first derivative (via Taylor approximation) of the log \\Gamma function\n",
    "    # according to Wikipedia this is the \"digamma\" function\n",
    "    return scipy.special.digamma(gamma_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood_smoothed(phi, gamma, alpha, Lambda, document, vocabulary, digamma_lambda, k, V):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "    #E_log_betai_givenLambda = lambda i:  (psi(Lambda[i].T) - psi(np.sum(Lambda))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "                \n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            term_knSum += phi[n,i] * digamma_lambda[i]\n",
    "\n",
    "    \n",
    "    L_terms = term0 + term_knSum + term_kSum \n",
    "    \n",
    "    return L_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma(k, phi, gamma, alpha, beta, document, vocabulary, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    iterations = 0\n",
    "    converged = False\n",
    "    \n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (iterations < MAX_STEPS):\n",
    "        iterations += 1\n",
    "            \n",
    "        phi_old = phi.copy()\n",
    "        gamma_old = gamma.copy()\n",
    "\n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                for i in range(k):                \n",
    "                    beta_ = beta[i, np.where(vocabulary == word)]\n",
    "                    phi[n, i] = beta_[0][0] * np.exp(digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "                phi[n,:] = phi[n,:] / np.sum(phi[n,:])   \n",
    "        \n",
    "        \n",
    "        gamma = alpha + np.sum(phi, axis=0)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print(str(iterations) + ' iterations to converge.')\n",
    "                \n",
    "            likelihood += compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k)\n",
    "            converged = True\n",
    "    \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma_smoothed(k, M, V, phi, gamma, alpha, eta, Lambda, documents, vocabulary, document, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda.T) - digamma(np.sum(Lambda, axis = 1))\n",
    "    \n",
    "    for d in range(M):\n",
    "        likelihood = -0.00001\n",
    "        iterations = 0\n",
    "        converged = False\n",
    "        \n",
    "        words = np.array(documents[d])\n",
    "        N = len(words)\n",
    "\n",
    "        while (not converged) and (iterations < MAX_STEPS):\n",
    "            iterations += 1\n",
    "            \n",
    "            phi_old = phi[d].copy()\n",
    "            gamma_old = gamma[d].copy()\n",
    "\n",
    "            digamma_gamma = digamma(gamma[d,:]) - digamma(np.sum(gamma[d,:]))\n",
    "            N = len(documents[d])\n",
    "            \n",
    "            for n in range(N):\n",
    "                word = words[n]\n",
    "                if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                    for i in range(k):\n",
    "                        temp_2 = digamma_gamma[i] + digamma_lambda[d][i]\n",
    "                        phi[d][n, i] = np.exp(temp_2)\n",
    "                    phi[d][n,:] =  phi[d][n,:] / np.sum(phi[d][n,:] + tol)\n",
    "            \n",
    "            gamma[d] = alpha + np.sum(phi[d], axis=0) \n",
    "            \n",
    "\n",
    "            # Convergence ctierion: did phi and gamma change significantly?            \n",
    "            if (np.linalg.norm(phi[d] - phi_old) < tol) and (np.linalg.norm(gamma[d] - gamma_old) < tol):              \n",
    "                print(str(iterations) + ' iterations to converge.')\n",
    "\n",
    "                likelihood += compute_lower_bound_likelihood_smoothed(phi[d], gamma[d], alpha, Lambda, document, vocabulary, digamma_lambda[d], k, V)\n",
    "                converged = True\n",
    "\n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(phi, eta, Lambda, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    Lambda = np.ones([k, V]) * eta\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                Lambda[i][j] += np.dot(indicator, phi_)\n",
    "\n",
    "    return Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(phi, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = np.zeros([k, V])\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                beta[i][j] += np.dot(indicator, phi_)\n",
    "    beta = np.transpose(np.transpose(beta) / np.sum(beta, axis=1))\n",
    "\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha, gamma, k, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "    # Maria B version\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = M * (k * special.polygamma(1, alpha) - special.polygamma(1, k*alpha))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = M * k * (k * special.polygamma(2, k*alpha) - special.polygamma(2, alpha))\n",
    "\n",
    "    temp = gradient / (hessian * alpha + gradient + tol)\n",
    "    if (alpha == 0).any():\n",
    "        alpha += 0.005\n",
    "\n",
    "    log_alpha = np.log(alpha) - temp\n",
    "    alpha = np.exp(log_alpha)    \n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eta(eta, gamma, k, V, M, max_iter=50, tol=1e-4):\n",
    "\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = V * (k * special.polygamma(1, eta) - special.polygamma(1, k*eta))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = V * k * (k * special.polygamma(2, k*eta) - special.polygamma(2, eta))\n",
    "\n",
    "    temp = gradient / (hessian * eta + gradient + tol)\n",
    "    if (eta == 0):\n",
    "        eta += 0.005\n",
    "\n",
    "    log_eta = np.log(eta) - temp\n",
    "    eta = np.exp(log_eta)    \n",
    "        \n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(phi, gamma, alpha, beta, documents, vocabulary, k):\n",
    "    print('E-step')\n",
    "    \n",
    "    for d, doc in enumerate(documents):\n",
    "        phi[d], gamma[d], likelihood = update_phi_gamma(k, phi[d], gamma[d], alpha, beta, doc, vocabulary)\n",
    "                \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step_smoothed(phi, gamma, alpha, eta, Lambda, documents, vocabulary, k):\n",
    "    print('E-step')\n",
    "    \n",
    "    V = len(vocabulary)\n",
    "\n",
    "    phi, gamma, likelihood = update_phi_gamma_smoothed(k, M, V, phi, gamma, alpha, eta, Lambda, documents, vocabulary, Lambda)\n",
    "    Lambda = update_lambda(phi, eta, Lambda, documents, vocabulary, k)\n",
    "        \n",
    "    return phi, gamma, Lambda, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(phi, gamma, alpha, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = update_beta(phi, documents, vocabulary, k)\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    eta = update_eta(eta, gamma, k, V, M)\n",
    "\n",
    "    return alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM(phi_init, gamma_init, alpha_init, beta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "    \n",
    "        phi, gamma, likelihood = \\\n",
    "            E_step(phi_old, gamma_old, alpha_old, beta_old, documents, vocabulary, k)\n",
    "        alpha, Beta = \\\n",
    "            M_step(phi, gamma, alpha_old, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, alpha, Beta, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    Lambda = Lambda_init\n",
    "    eta = eta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "        Lambda_old = Lambda\n",
    "        eta_old = eta\n",
    "        \n",
    "    \n",
    "        phi, gamma, Lambda, likelihood = \\\n",
    "            E_step_smoothed( phi_old, gamma_old, alpha_old, eta_old, Lambda_old, documents, vocabulary, k)\n",
    "        alpha, eta = \\\n",
    "            M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "            \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood - likelihood_old) / likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, Lambda, alpha, eta, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "corpus_reduced = corpus[:50]\n",
    "M = len(corpus_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "E-step\n",
      "53 iterations to converge.\n",
      "57 iterations to converge.\n",
      "49 iterations to converge.\n",
      "45 iterations to converge.\n",
      "25 iterations to converge.\n",
      "79 iterations to converge.\n",
      "43 iterations to converge.\n",
      "23 iterations to converge.\n",
      "8 iterations to converge.\n",
      "38 iterations to converge.\n",
      "19 iterations to converge.\n",
      "29 iterations to converge.\n",
      "44 iterations to converge.\n",
      "13 iterations to converge.\n",
      "63 iterations to converge.\n",
      "36 iterations to converge.\n",
      "45 iterations to converge.\n",
      "63 iterations to converge.\n",
      "46 iterations to converge.\n",
      "74 iterations to converge.\n",
      "21 iterations to converge.\n",
      "9 iterations to converge.\n",
      "8 iterations to converge.\n",
      "21 iterations to converge.\n",
      "74 iterations to converge.\n",
      "49 iterations to converge.\n",
      "57 iterations to converge.\n",
      "32 iterations to converge.\n",
      "73 iterations to converge.\n",
      "52 iterations to converge.\n",
      "71 iterations to converge.\n",
      "66 iterations to converge.\n",
      "21 iterations to converge.\n",
      "30 iterations to converge.\n",
      "51 iterations to converge.\n",
      "33 iterations to converge.\n",
      "63 iterations to converge.\n",
      "47 iterations to converge.\n",
      "57 iterations to converge.\n",
      "29 iterations to converge.\n",
      "65 iterations to converge.\n",
      "36 iterations to converge.\n",
      "73 iterations to converge.\n",
      "29 iterations to converge.\n",
      "42 iterations to converge.\n",
      "46 iterations to converge.\n",
      "28 iterations to converge.\n",
      "60 iterations to converge.\n",
      "45 iterations to converge.\n",
      "64 iterations to converge.\n",
      "M-step\n",
      "E-step\n",
      "65 iterations to converge.\n",
      "70 iterations to converge.\n",
      "62 iterations to converge.\n",
      "58 iterations to converge.\n",
      "34 iterations to converge.\n",
      "89 iterations to converge.\n",
      "57 iterations to converge.\n",
      "33 iterations to converge.\n",
      "10 iterations to converge.\n",
      "52 iterations to converge.\n",
      "26 iterations to converge.\n",
      "40 iterations to converge.\n",
      "53 iterations to converge.\n",
      "17 iterations to converge.\n",
      "70 iterations to converge.\n",
      "47 iterations to converge.\n",
      "58 iterations to converge.\n",
      "73 iterations to converge.\n",
      "57 iterations to converge.\n",
      "84 iterations to converge.\n",
      "28 iterations to converge.\n",
      "11 iterations to converge.\n",
      "9 iterations to converge.\n",
      "29 iterations to converge.\n",
      "88 iterations to converge.\n",
      "62 iterations to converge.\n",
      "72 iterations to converge.\n",
      "44 iterations to converge.\n",
      "84 iterations to converge.\n",
      "62 iterations to converge.\n",
      "78 iterations to converge.\n",
      "77 iterations to converge.\n",
      "29 iterations to converge.\n",
      "42 iterations to converge.\n",
      "64 iterations to converge.\n",
      "44 iterations to converge.\n",
      "69 iterations to converge.\n",
      "62 iterations to converge.\n",
      "71 iterations to converge.\n",
      "39 iterations to converge.\n",
      "78 iterations to converge.\n",
      "38 iterations to converge.\n",
      "82 iterations to converge.\n",
      "38 iterations to converge.\n",
      "54 iterations to converge.\n",
      "56 iterations to converge.\n",
      "37 iterations to converge.\n",
      "67 iterations to converge.\n",
      "57 iterations to converge.\n",
      "76 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, alpha, beta, likelihood = \\\n",
    "        variational_EM(phi_init, gamma_init, alpha_init, beta_init, corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: smoothed LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_s, gamma_s, lambda_s, alpha_s, eta_s, likelihood_s = \\\n",
    "variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, corpus_reduced, vocabulary, k, tol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(gamma.T)\n",
    "plt.xlabel(\"Documents\")\n",
    "plt.ylabel(\"topic 1..k\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolormesh(Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = beta[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-5:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['million', 'people', 'text', 'ap', 'gas', 'dukakis', 'waste', 'new', 'doc', 'bank']\n",
      "['officers', 'polish', 'text', 'ap', 'percent', 'new', 'years', 'rating', 'soviet', 'doc']\n",
      "['september', 'official', 'people', 'offer', 'year', 'prices', 'peres', 'oil', 'doc', 'percent']\n",
      "['national', 'monday', 'ap', 'text', 'police', 'bush', 'fire', 'year', 'doc', 'percent']\n",
      "['people', 'ap', 'text', 'officials', 'magellan', 'spacecraft', 'two', 'panama', 'noriega', 'doc']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    l_topic = lambda_s[l, :]\n",
    "    l_topic_top4 = np.argsort(l_topic)[-10:]\n",
    "    plt.plot(l_topic)\n",
    "    print([w for w in np.array(vocabulary)[l_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TEXT WITH COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The William Randolph Hearst Foundation will give  million to Lincoln Center Metropolitan Opera Co New York Philharmonic and Juilliard School Our board felt that we had a real opportunity to make a mark on the future of the performing arts with these grants  an act every bit as important as our traditional areas of support in health medical research education and the social services Hearst Foundation President Randolph A Hearst said Monday in announcing the grants Lincoln Centers share will be  for its new building which will house young artists and provide new public facilities The Metropolitan'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_text(corpus_file, number_of_text):\n",
    "    fulltext_words=[]\n",
    "    fulltext_allwords=[]\n",
    "    #number_of_text=2\n",
    "    text_counter=0\n",
    "    special_chars = '1234567890~!@#£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "\n",
    "    with open(corpus_file, 'r') as text:\n",
    "        new=False\n",
    "        for line in text:\n",
    "            if new:\n",
    "                #print(line.strip()[0], line.strip()[:10])\n",
    "                if line.strip()[0]==\"<\":\n",
    "                    pass\n",
    "                else:\n",
    "                    #print(\"FOUND\", text)\n",
    "                    text_counter+=1\n",
    "                    if text_counter==number_of_text:\n",
    "                        #print(\" CORRECT\")\n",
    "                        new_text=line\n",
    "                        fulltext=new_text\n",
    "                        words = np.array(new_text.split())\n",
    "                        for word in words:\n",
    "                            fulltext_allwords.append(word)\n",
    "                            for char in special_chars: # remove punctuation etc,\n",
    "                                word = word.replace(char, '') \n",
    "                            fulltext_words.append(word)\n",
    "\n",
    "\n",
    "            else:\n",
    "                if line.strip() == \"<TEXT>\":\n",
    "                    new=True\n",
    "    return fulltext_words, fulltext_allwords\n",
    "\n",
    "fulltext_words, fulltext_allwords = get_full_text('ap/ap.txt', 1358)\n",
    "\" \".join(fulltext_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['blue','green', 'red', 'yellow', 'magenta']\n",
    "colors_ansi=[34, 32, 31, 33, 35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give= 3, million= 4, board= 1, felt= 1, real= 2, opportunity= 0, mark= 4, future= 2, arts= 4, bit= 2, important= 0, traditional= 4, areas= 1, support= 0, health= 0, medical= 4, research= 3, education= 3, social= 4, share= 0, new= 4, building= 3, young= 1, provide= 4, new= 4, public= 3, facilities= 1, receive= 0, music= 0, arts= 4, leading= 3, supporter= 4, annual= 3, "
     ]
    }
   ],
   "source": [
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=1.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in vocabulary:\n",
    "        v = np.where(vocabulary==word)[0][0]\n",
    "        #print(v,word_beta )\n",
    "        word_beta = beta[:,v]\n",
    "        #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "        if np.max(word_beta)>np.mean(beta):\n",
    "            if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                color = colors[topic]\n",
    "                print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "            else:\n",
    "                color='k'\n",
    "        else:\n",
    "            color='k'\n",
    "    else: \n",
    "        color='k'\n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://ozzmaker.com/add-colour-to-text-in-python/\n",
    "#print(\"Examples of how to use ANSI COLOR: \\033[1;37;40m White          \\033[0m 1;37;40m            \\033[0;37;40m Light Grey \\033[0m 0;37;40m               \\033[0;37;48m Black      \\033[0m 0;37;48m\")\n",
    "             \n",
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "million= 0, felt= 3, real= 0, make= 4, mark= 1, future= 0, arts= 3, act= 4, traditional= 3, areas= 4, support= 0, education= 0, social= 2, share= 0, new= 0, house= 4, artists= 1, new= 0, public= 4, facilities= 4, music= 3, arts= 3, leading= 3, make= 4, "
     ]
    }
   ],
   "source": [
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=1.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in vocabulary:\n",
    "        v = np.where(vocabulary==word)[0][0]\n",
    "        #print(v,word_beta )\n",
    "        word_l = lambda_s[:,v]\n",
    "        #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "        if np.max(word_l)>np.mean(Lambda):\n",
    "            if np.max(word_l)> how_significant*np.mean(word_l):\n",
    "                #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                topic = np.where(np.max(word_l)==word_l)[0][0]\n",
    "                color = colors[topic]\n",
    "                print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "            else:\n",
    "                color='k'\n",
    "        else:\n",
    "            color='k'\n",
    "    else: \n",
    "        color='k'\n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mThe \u001b[0mWilliam \u001b[0mRandolph \u001b[0mHearst \u001b[0mFoundation \u001b[0mwill \u001b[0mgive \u001b[0m$1.25 \u001b[0;34;48mmillion \u001b[0mto \u001b[0mLincoln \u001b[0mCenter, \u001b[0mMetropolitan \u001b[0mOpera \u001b[0mCo., \u001b[0mNew \u001b[0mYork \u001b[0mPhilharmonic \u001b[0mand \u001b[0mJuilliard \u001b[0mSchool. \u001b[0m``Our \u001b[0mboard \u001b[0;33;48mfelt \u001b[0mthat \u001b[0mwe \u001b[0mhad \u001b[0ma \u001b[0;34;48mreal \u001b[0mopportunity \u001b[0mto \u001b[0;35;48mmake \u001b[0ma \u001b[0;32;48mmark \u001b[0mon \u001b[0mthe \u001b[0;34;48mfuture \u001b[0mof \u001b[0mthe \u001b[0mperforming \u001b[0;33;48marts \u001b[0mwith \u001b[0mthese \u001b[0mgrants \u001b[0m_ \u001b[0man \u001b[0;35;48mact \u001b[0mevery \u001b[0mbit \u001b[0mas \u001b[0mimportant \u001b[0mas \u001b[0mour \u001b[0;33;48mtraditional \u001b[0;35;48mareas \u001b[0mof \u001b[0;34;48msupport \u001b[0min \u001b[0mhealth, \u001b[0mmedical \u001b[0mresearch, \u001b[0;34;48meducation \u001b[0mand \u001b[0mthe \u001b[0;31;48msocial \u001b[0mservices,'' \u001b[0mHearst \u001b[0mFoundation \u001b[0mPresident \u001b[0mRandolph \u001b[0mA. \u001b[0mHearst \u001b[0msaid \u001b[0mMonday \u001b[0min \u001b[0mannouncing \u001b[0mthe \u001b[0mgrants. \u001b[0mLincoln \u001b[0mCenter's \u001b[0;34;48mshare \u001b[0mwill \u001b[0mbe \u001b[0m$200,000 \u001b[0mfor \u001b[0mits \u001b[0;34;48mnew \u001b[0mbuilding, \u001b[0mwhich \u001b[0mwill \u001b[0;35;48mhouse \u001b[0myoung \u001b[0;32;48martists \u001b[0mand \u001b[0mprovide \u001b[0;34;48mnew \u001b[0;35;48mpublic \u001b[0;35;48mfacilities. \u001b[0mThe \u001b[0mMetropolitan \u001b[0mOpera \u001b[0mCo. \u001b[0mand \u001b[0mNew \u001b[0mYork \u001b[0mPhilharmonic \u001b[0mwill \u001b[0mreceive \u001b[0m$400,000 \u001b[0meach. \u001b[0mThe \u001b[0mJuilliard \u001b[0mSchool, \u001b[0mwhere \u001b[0;33;48mmusic \u001b[0mand \u001b[0mthe \u001b[0mperforming \u001b[0;33;48marts \u001b[0mare \u001b[0mtaught, \u001b[0mwill \u001b[0mget \u001b[0m$250,000. \u001b[0mThe \u001b[0mHearst \u001b[0mFoundation, \u001b[0ma \u001b[0;33;48mleading \u001b[0msupporter \u001b[0mof \u001b[0mthe \u001b[0mLincoln \u001b[0mCenter \u001b[0mConsolidated \u001b[0mCorporate \u001b[0mFund, \u001b[0mwill \u001b[0;35;48mmake \u001b[0mits \u001b[0musual \u001b[0mannual \u001b[0m$100,000 \u001b[0mdonation, \u001b[0mtoo. "
     ]
    }
   ],
   "source": [
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48mmillion, real, future, support, education, share, new, new\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48mmark, artists\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48msocial\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 3: \u001b[0;33;48mfelt, arts, traditional, music, arts, leading\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 4: \u001b[0;35;48mmake, act, areas, house, public, facilities, make\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REUTERS DATA (get from the external program to keep this a bit tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getReuters import D_reuters as corpus_reuters\n",
    "from getReuters import vocab_list as vocabulary_reuters\n",
    "vocabulary_reuters=np.array(vocabulary_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_reuters = 5\n",
    "corpus_reuters_reduced = corpus_reuters[:50]\n",
    "M_reuters = len(corpus_reuters_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init_reuters, eta_init_reuters, beta_init_reuters, gamma_init_reuters, phi_init_reuters, Lambda_init_reuters =\\\n",
    "    initialize_parameters(corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_reuters, gamma_reuters, alpha_reuters, Beta_reuters, likelihood_reuters = \\\n",
    "        variational_EM(phi_init_reuters, gamma_init_reuters, alpha_init_reuters, beta_init_reuters, \n",
    "                       corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Analysis for REUTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(Beta_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['election', 'space', 'thursday', 'white', 'party', 'six', 'judge', 'proposed', 'things', 'told']\n",
      "['countries', 'health', 'election', 'told', 'six', 'proposed', 'vice', 'things', 'day', 'party']\n",
      "['thursday', 'election', 'workers', 'proposed', 'bill', 'countries', 'day', 'things', 'vice', 'told']\n",
      "['thursday', 'gorbachev', 'space', 'white', 'death', 'food', 'election', 'six', 'judge', 'party']\n",
      "['party', 'countries', 'day', 'catholic', 'judge', 'past', 'white', 'gorbachev', 'vice', 'told']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = Beta_reuters[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-10:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\Mimi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<CategorizedPlaintextCorpusReader in 'C:\\\\Users\\\\Mimi\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\reuters.zip/reuters/'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulltext_words = corpus_reuters[0]\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "nltk.corpus.reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "again\n",
      "with\n",
      "there\n",
      "in\n",
      "s\n",
      "but\n",
      "a\n",
      "up\n",
      "was\n",
      "she\n",
      "i\n",
      "we\n",
      "and\n",
      "most\n",
      "to\n",
      "be\n",
      "against\n",
      "they\n",
      "of\n",
      "d\n",
      "it\n",
      "on\n",
      "off\n",
      "from\n",
      "he\n",
      "such\n",
      "by\n",
      "for\n",
      "at\n",
      "does\n",
      "not\n",
      "is\n",
      "further\n",
      "this\n",
      "an\n",
      "after\n",
      "no\n",
      "under\n",
      "t\n",
      "some\n",
      "will\n",
      "his\n",
      "me\n",
      "these\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "new = []\n",
    "\n",
    "for w in vocabulary_reuters:\n",
    "    if w in nltk.corpus.stopwords.words(\"english\"):\n",
    "        #print(w)\n",
    "        pass\n",
    "    else: \n",
    "        new.append(w)\n",
    "        \n",
    "vocbulary_reuters = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=1.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in nltk.corpus.stopwords.words(\"english\"):\n",
    "        color = \"k\"\n",
    "    else:\n",
    "        if word in vocabulary_reuters:\n",
    "            v = np.where(vocabulary_reuters==word)[0][0]\n",
    "            #print(word)\n",
    "            word_beta = Beta_reuters[:,v]\n",
    "            #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "            if np.max(word_beta)>np.mean(beta):\n",
    "                if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                    #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                    topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                    color = colors[topic]\n",
    "                    #print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "                else:\n",
    "                    color='k'\n",
    "            else:\n",
    "                color='k'\n",
    "        else: \n",
    "            color='k'\n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mThe \u001b[0mWilliam \u001b[0mRandolph \u001b[0mHearst \u001b[0mFoundation \u001b[0mwill \u001b[0;34;48mgive \u001b[0m$1.25 \u001b[0mmillion \u001b[0mto \u001b[0mLincoln \u001b[0mCenter, \u001b[0mMetropolitan \u001b[0mOpera \u001b[0mCo., \u001b[0mNew \u001b[0mYork \u001b[0mPhilharmonic \u001b[0mand \u001b[0mJuilliard \u001b[0mSchool. \u001b[0m``Our \u001b[0;31;48mboard \u001b[0mfelt \u001b[0mthat \u001b[0mwe \u001b[0mhad \u001b[0ma \u001b[0;34;48mreal \u001b[0mopportunity \u001b[0mto \u001b[0mmake \u001b[0ma \u001b[0mmark \u001b[0mon \u001b[0mthe \u001b[0;35;48mfuture \u001b[0mof \u001b[0mthe \u001b[0mperforming \u001b[0marts \u001b[0mwith \u001b[0mthese \u001b[0mgrants \u001b[0m_ \u001b[0man \u001b[0;31;48mact \u001b[0mevery \u001b[0mbit \u001b[0mas \u001b[0mimportant \u001b[0mas \u001b[0mour \u001b[0mtraditional \u001b[0mareas \u001b[0mof \u001b[0;32;48msupport \u001b[0min \u001b[0mhealth, \u001b[0mmedical \u001b[0mresearch, \u001b[0meducation \u001b[0mand \u001b[0mthe \u001b[0msocial \u001b[0;34;48mservices,'' \u001b[0mHearst \u001b[0mFoundation \u001b[0mPresident \u001b[0mRandolph \u001b[0mA. \u001b[0mHearst \u001b[0;35;48msaid \u001b[0mMonday \u001b[0min \u001b[0mannouncing \u001b[0mthe \u001b[0mgrants. \u001b[0mLincoln \u001b[0mCenter's \u001b[0;34;48mshare \u001b[0mwill \u001b[0mbe \u001b[0m$200,000 \u001b[0mfor \u001b[0mits \u001b[0mnew \u001b[0mbuilding, \u001b[0mwhich \u001b[0mwill \u001b[0mhouse \u001b[0myoung \u001b[0martists \u001b[0mand \u001b[0mprovide \u001b[0mnew \u001b[0;32;48mpublic \u001b[0mfacilities. \u001b[0mThe \u001b[0mMetropolitan \u001b[0mOpera \u001b[0mCo. \u001b[0mand \u001b[0mNew \u001b[0mYork \u001b[0mPhilharmonic \u001b[0mwill \u001b[0mreceive \u001b[0m$400,000 \u001b[0meach. \u001b[0mThe \u001b[0mJuilliard \u001b[0mSchool, \u001b[0mwhere \u001b[0mmusic \u001b[0mand \u001b[0mthe \u001b[0mperforming \u001b[0marts \u001b[0mare \u001b[0mtaught, \u001b[0mwill \u001b[0;35;48mget \u001b[0m$250,000. \u001b[0mThe \u001b[0mHearst \u001b[0mFoundation, \u001b[0ma \u001b[0mleading \u001b[0msupporter \u001b[0mof \u001b[0mthe \u001b[0mLincoln \u001b[0mCenter \u001b[0mConsolidated \u001b[0mCorporate \u001b[0mFund, \u001b[0mwill \u001b[0mmake \u001b[0mits \u001b[0musual \u001b[0;31;48mannual \u001b[0m$100,000 \u001b[0mdonation, \u001b[0mtoo. "
     ]
    }
   ],
   "source": [
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48mgive, real, services, share\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48msupport, public\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48mboard, act, annual\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 3: \u001b[0;33;48m\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 4: \u001b[0;35;48mfuture, said, get\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"reuters0.txt\"\n",
    "fulltext_words=[]\n",
    "fulltext_allwords=[]\n",
    "#number_of_text=2\n",
    "text_counter=0\n",
    "special_chars = '1234567890~!@#£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "\n",
    "with open(corpus_file, 'r') as text:\n",
    "    new=False\n",
    "    for line in text:\n",
    "        new_text=line\n",
    "        fulltext=new_text\n",
    "        words = np.array(new_text.split())\n",
    "        for word in words:\n",
    "            fulltext_allwords.append(word)\n",
    "            for char in special_chars: # remove punctuation etc,\n",
    "                word = word.replace(char, '') \n",
    "            fulltext_words.append(word)\n",
    "\n",
    "\n",
    "        else:\n",
    "            if line.strip() == \"<TEXT>\":\n",
    "                new=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=1.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in nltk.corpus.stopwords.words(\"english\"):\n",
    "        color = 'k'\n",
    "    else:\n",
    "        if word in vocabulary_reuters:\n",
    "            v = np.where(vocabulary_reuters==word)[0][0]\n",
    "            #print(word)\n",
    "            word_beta = Beta_reuters[:,v]\n",
    "            #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "            if np.max(word_beta)>np.mean(beta):\n",
    "                if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                    #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                    topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                    color = colors[topic]\n",
    "                    #print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "                else:\n",
    "                    color='k'\n",
    "            else:\n",
    "                color='k'\n",
    "        else: \n",
    "            color='k'\n",
    "            \n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mBAHIA \u001b[0mCOCOA \u001b[0mREVIEW \u001b[0mShowers \u001b[0;32;48mcontinued \u001b[0;31;48mthroughout \u001b[0mthe \u001b[0;32;48mweek \u001b[0min \u001b[0mthe \u001b[0mBahia \u001b[0;33;48mcocoa \u001b[0;32;48mzone, \u001b[0;33;48malleviating \u001b[0mthe \u001b[0;31;48mdrought \u001b[0;34;48msince \u001b[0;35;48mearly \u001b[0mJanuary \u001b[0mand \u001b[0;32;48mimproving \u001b[0;31;48mprospects \u001b[0mfor \u001b[0mthe \u001b[0;31;48mcoming \u001b[0;31;48mtemporao, \u001b[0;34;48malthough \u001b[0;31;48mnormal \u001b[0;32;48mhumidity \u001b[0;32;48mlevels \u001b[0mhave \u001b[0mnot \u001b[0mbeen \u001b[0;32;48mrestored, \u001b[0mComissaria \u001b[0mSmith \u001b[0;35;48msaid \u001b[0min \u001b[0mits \u001b[0;33;48mweekly \u001b[0;32;48mreview. \u001b[0mThe \u001b[0;35;48mdry \u001b[0mperiod \u001b[0;31;48mmeans \u001b[0mthe \u001b[0;31;48mtemporao \u001b[0mwill \u001b[0mbe \u001b[0;31;48mlate \u001b[0mthis \u001b[0;32;48myear. \u001b[0mArrivals \u001b[0mfor \u001b[0mthe \u001b[0;32;48mweek \u001b[0;32;48mended \u001b[0mFebruary \u001b[0m22 \u001b[0mwere \u001b[0m155,221 \u001b[0;33;48mbags \u001b[0mof \u001b[0m60 \u001b[0;35;48mkilos \u001b[0;34;48mmaking \u001b[0ma \u001b[0;31;48mcumulative \u001b[0;33;48mtotal \u001b[0mfor \u001b[0mthe \u001b[0;31;48mseason \u001b[0mof \u001b[0m5.93 \u001b[0mmln \u001b[0magainst \u001b[0m5.81 \u001b[0mat \u001b[0mthe \u001b[0msame \u001b[0;32;48mstage \u001b[0;31;48mlast \u001b[0;32;48myear. \u001b[0mAgain \u001b[0mit \u001b[0;32;48mseems \u001b[0mthat \u001b[0;33;48mcocoa \u001b[0;34;48mdelivered \u001b[0;35;48mearlier \u001b[0mon \u001b[0;31;48mconsignment \u001b[0mwas \u001b[0;33;48mincluded \u001b[0min \u001b[0mthe \u001b[0;31;48marrivals \u001b[0;31;48mfigures. \u001b[0mComissaria \u001b[0mSmith \u001b[0;35;48msaid \u001b[0mthere \u001b[0mis \u001b[0;32;48mstill \u001b[0msome \u001b[0;32;48mdoubt \u001b[0mas \u001b[0mto \u001b[0mhow \u001b[0;34;48mmuch \u001b[0;34;48mold \u001b[0;31;48mcrop \u001b[0;33;48mcocoa \u001b[0mis \u001b[0;32;48mstill \u001b[0;34;48mavailable \u001b[0mas \u001b[0;32;48mharvesting \u001b[0mhas \u001b[0;32;48mpractically \u001b[0mcome \u001b[0mto \u001b[0man \u001b[0mend. \u001b[0mWith \u001b[0;33;48mtotal \u001b[0mBahia \u001b[0;31;48mcrop \u001b[0;32;48mestimates \u001b[0;33;48maround \u001b[0m6.4 \u001b[0mmln \u001b[0;33;48mbags \u001b[0mand \u001b[0;33;48msales \u001b[0;32;48mstanding \u001b[0mat \u001b[0;34;48malmost \u001b[0m6.2 \u001b[0mmln \u001b[0mthere \u001b[0mare \u001b[0ma \u001b[0mfew \u001b[0;32;48mhundred \u001b[0;32;48mthousand \u001b[0;33;48mbags \u001b[0;32;48mstill \u001b[0min \u001b[0mthe \u001b[0;32;48mhands \u001b[0mof \u001b[0;32;48mfarmers, \u001b[0;35;48mmiddlemen, \u001b[0;32;48mexporters \u001b[0mand \u001b[0mprocessors. \u001b[0mThere \u001b[0mare \u001b[0;31;48mdoubts \u001b[0mas \u001b[0mto \u001b[0mhow \u001b[0;34;48mmuch \u001b[0mof \u001b[0mthis \u001b[0;33;48mcocoa \u001b[0mwould \u001b[0mbe \u001b[0;32;48mfit \u001b[0mfor \u001b[0;34;48mexport \u001b[0mas \u001b[0;35;48mshippers \u001b[0mare \u001b[0mnow \u001b[0;31;48mexperiencing \u001b[0;32;48mdificulties \u001b[0min \u001b[0;34;48mobtaining \u001b[0m+Bahia \u001b[0;33;48msuperior+ \u001b[0;32;48mcertificates. \u001b[0mIn \u001b[0;32;48mview \u001b[0mof \u001b[0mthe \u001b[0;31;48mlower \u001b[0;32;48mquality \u001b[0mover \u001b[0;34;48mrecent \u001b[0;32;48mweeks \u001b[0;32;48mfarmers \u001b[0mhave \u001b[0msold \u001b[0ma \u001b[0;35;48mgood \u001b[0mpart \u001b[0mof \u001b[0mtheir \u001b[0;33;48mcocoa \u001b[0;32;48mheld \u001b[0mon \u001b[0;31;48mconsignment. \u001b[0mComissaria \u001b[0mSmith \u001b[0;35;48msaid \u001b[0;32;48mspot \u001b[0;32;48mbean \u001b[0;35;48mprices \u001b[0;31;48mrose \u001b[0mto \u001b[0m340 \u001b[0mto \u001b[0m350 \u001b[0;32;48mcruzados \u001b[0mper \u001b[0;32;48marroba \u001b[0mof \u001b[0m15 \u001b[0;35;48mkilos. \u001b[0mBean \u001b[0;35;48mshippers \u001b[0mwere \u001b[0;31;48mreluctant \u001b[0mto \u001b[0;35;48moffer \u001b[0;31;48mnearby \u001b[0;35;48mshipment \u001b[0mand \u001b[0monly \u001b[0;34;48mlimited \u001b[0;33;48msales \u001b[0mwere \u001b[0;32;48mbooked \u001b[0mfor \u001b[0mMarch \u001b[0;35;48mshipment \u001b[0mat \u001b[0m1,750 \u001b[0mto \u001b[0m1,780 \u001b[0;35;48mdlrs \u001b[0mper \u001b[0;34;48mtonne \u001b[0mto \u001b[0mports \u001b[0mto \u001b[0mbe \u001b[0;31;48mnamed. \u001b[0mNew \u001b[0;31;48mcrop \u001b[0;33;48msales \u001b[0mwere \u001b[0;35;48malso \u001b[0;34;48mlight \u001b[0mand \u001b[0mall \u001b[0mto \u001b[0;32;48mopen \u001b[0mports \u001b[0mwith \u001b[0mJune/July \u001b[0;35;48mgoing \u001b[0mat \u001b[0m1,850 \u001b[0mand \u001b[0m1,880 \u001b[0;35;48mdlrs \u001b[0mand \u001b[0mat \u001b[0m35 \u001b[0mand \u001b[0m45 \u001b[0;35;48mdlrs \u001b[0munder \u001b[0mNew \u001b[0mYork \u001b[0;35;48mjuly, \u001b[0mAug/Sept \u001b[0mat \u001b[0m1,870, \u001b[0m1,875 \u001b[0mand \u001b[0m1,880 \u001b[0;35;48mdlrs \u001b[0mper \u001b[0;34;48mtonne \u001b[0mFOB. \u001b[0mRoutine \u001b[0;33;48msales \u001b[0mof \u001b[0mbutter \u001b[0mwere \u001b[0mmade. \u001b[0mMarch/April \u001b[0msold \u001b[0mat \u001b[0m4,340, \u001b[0m4,345 \u001b[0mand \u001b[0m4,350 \u001b[0;35;48mdlrs. \u001b[0mApril/May \u001b[0mbutter \u001b[0;33;48mwent \u001b[0mat \u001b[0m2.27 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mMay, \u001b[0mJune/July \u001b[0mat \u001b[0m4,400 \u001b[0mand \u001b[0m4,415 \u001b[0;35;48mdlrs, \u001b[0mAug/Sept \u001b[0mat \u001b[0m4,351 \u001b[0mto \u001b[0m4,450 \u001b[0;35;48mdlrs \u001b[0mand \u001b[0mat \u001b[0m2.27 \u001b[0mand \u001b[0m2.28 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mSept \u001b[0mand \u001b[0mOct/Dec \u001b[0mat \u001b[0m4,480 \u001b[0;35;48mdlrs \u001b[0mand \u001b[0m2.27 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mDec, \u001b[0mComissaria \u001b[0mSmith \u001b[0;35;48msaid. \u001b[0mDestinations \u001b[0mwere \u001b[0mthe \u001b[0mU.S., \u001b[0mCovertible \u001b[0;31;48mcurrency \u001b[0mareas, \u001b[0mUruguay \u001b[0mand \u001b[0;32;48mopen \u001b[0mports. \u001b[0mCake \u001b[0;33;48msales \u001b[0mwere \u001b[0;31;48mregistered \u001b[0mat \u001b[0m785 \u001b[0mto \u001b[0m995 \u001b[0;35;48mdlrs \u001b[0mfor \u001b[0mMarch/April, \u001b[0m785 \u001b[0;35;48mdlrs \u001b[0mfor \u001b[0mMay, \u001b[0m753 \u001b[0;35;48mdlrs \u001b[0mfor \u001b[0mAug \u001b[0mand \u001b[0m0.39 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mDec \u001b[0mfor \u001b[0mOct/Dec. \u001b[0mBuyers \u001b[0mwere \u001b[0mthe \u001b[0mU.S., \u001b[0mArgentina, \u001b[0mUruguay \u001b[0mand \u001b[0;32;48mconvertible \u001b[0;31;48mcurrency \u001b[0mareas. \u001b[0mLiquor \u001b[0;33;48msales \u001b[0mwere \u001b[0;34;48mlimited \u001b[0mwith \u001b[0mMarch/April \u001b[0;32;48mselling \u001b[0mat \u001b[0m2,325 \u001b[0mand \u001b[0m2,380 \u001b[0;35;48mdlrs, \u001b[0mJune/July \u001b[0mat \u001b[0m2,375 \u001b[0;35;48mdlrs \u001b[0mand \u001b[0mat \u001b[0m1.25 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mJuly, \u001b[0mAug/Sept \u001b[0mat \u001b[0m2,400 \u001b[0;35;48mdlrs \u001b[0mand \u001b[0mat \u001b[0m1.25 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mSept \u001b[0mand \u001b[0mOct/Dec \u001b[0mat \u001b[0m1.25 \u001b[0;31;48mtimes \u001b[0mNew \u001b[0mYork \u001b[0mDec, \u001b[0mComissaria \u001b[0mSmith \u001b[0;35;48msaid. \u001b[0mTotal \u001b[0mBahia \u001b[0;33;48msales \u001b[0mare \u001b[0;32;48mcurrently \u001b[0mestimated \u001b[0mat \u001b[0m6.13 \u001b[0mmln \u001b[0;33;48mbags \u001b[0magainst \u001b[0mthe \u001b[0m1986/87 \u001b[0;31;48mcrop \u001b[0mand \u001b[0m1.06 \u001b[0mmln \u001b[0;33;48mbags \u001b[0magainst \u001b[0mthe \u001b[0m1987/88 \u001b[0;31;48mcrop. \u001b[0mFinal \u001b[0;31;48mfigures \u001b[0mfor \u001b[0mthe \u001b[0mperiod \u001b[0mto \u001b[0mFebruary \u001b[0m28 \u001b[0mare \u001b[0;32;48mexpected \u001b[0mto \u001b[0mbe \u001b[0;35;48mpublished \u001b[0mby \u001b[0mthe \u001b[0mBrazilian \u001b[0mCocoa \u001b[0mTrade \u001b[0mCommission \u001b[0mafter \u001b[0;32;48mcarnival \u001b[0mwhich \u001b[0;31;48mends \u001b[0;31;48mmidday \u001b[0mon \u001b[0mFebruary \u001b[0m27. "
     ]
    }
   ],
   "source": [
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48msince, although, making, delivered, much, old, available, almost, much, export, obtaining, recent, limited, tonne, light, tonne, limited\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48mcontinued, week, zone, improving, humidity, levels, restored, review, year, week, ended, stage, year, seems, still, doubt, still, harvesting, practically, estimates, standing, hundred, thousand, still, hands, farmers, exporters, fit, dificulties, certificates, view, quality, weeks, farmers, held, spot, bean, cruzados, arroba, booked, open, open, convertible, selling, currently, expected, carnival\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48mthroughout, drought, prospects, coming, temporao, normal, means, temporao, late, cumulative, season, last, consignment, arrivals, figures, crop, crop, doubts, experiencing, lower, consignment, rose, reluctant, nearby, named, crop, times, times, times, currency, registered, times, currency, times, times, times, crop, crop, figures, ends, midday\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 3: \u001b[0;33;48mcocoa, alleviating, weekly, bags, total, cocoa, included, cocoa, total, around, bags, sales, bags, cocoa, superior, cocoa, sales, sales, sales, went, sales, sales, sales, bags, bags\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 4: \u001b[0;35;48mearly, said, dry, kilos, earlier, said, middlemen, shippers, good, said, prices, kilos, shippers, offer, shipment, shipment, dlrs, also, going, dlrs, dlrs, july, dlrs, dlrs, dlrs, dlrs, dlrs, said, dlrs, dlrs, dlrs, dlrs, dlrs, dlrs, said, published\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2060"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_reuters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
