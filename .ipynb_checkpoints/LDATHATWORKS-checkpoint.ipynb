{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2434_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PARAMETERS:\n",
    "\n",
    "k - number of topics\n",
    "N - number of words in a document (different for each document)\n",
    "M - number of documents in a corpus\n",
    "\n",
    "Model parameters:\n",
    "z_n - [k] dimension vector; topic distribution for word n \n",
    "Theta - [k] dimension vector; mixture weights\n",
    "alpha - [k] dimension vector; prior probability for theta (mixture weights) (alpha > 0)\n",
    "beta - [k x V] dimension matrix; beta_ij = p(w^j = 1 | z^i = 1) \n",
    "                                 probability for a specific word j given a specific topic i\n",
    "D - list of [V x N] dimension matrices, that is M long = [\\mathbf{w}_1, ... \\mathbf{w}_M];\n",
    "                                 where \\mathbf{w} = [w_1,...,w_N] is [V x N] (one document consisting of N words) \n",
    "\n",
    "\n",
    "Variational parameters:\n",
    "Gamma - [k] dimension vector; determines Theta in the Variational Model\n",
    "Phi = phi_1 .. phi_N - [N x k] dimension matrix; determines the probability distribution \n",
    "                                 for topics z of words in the Variational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import special, misc\n",
    "from scipy.special import logsumexp\n",
    "from scipy.special import digamma, gammaln, polygamma\n",
    "import pandas as pd\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Document Corpus\n",
    "Download the data from \n",
    "https://github.com/Blei-Lab/lda-c/blob/master/example/ap.tgz\n",
    "\n",
    "We can directly load the file \"ap.dat\" which contains:\n",
    "\n",
    "1 line = 1 document,\n",
    "\n",
    "[number of different words in doc] [word index (where the one is in w_n]:[how often it occurs in the doc] [word index 2]:[occurences 2] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.genfromtxt('ap/vocab.txt',  dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data(corpus_file, vocabulary_file, stopwords_file):\n",
    "    \"\"\"\n",
    "    Reads the corpus from the .txt file into a list of lists;\n",
    "    a list for each document which contains a list of all the \n",
    "    words as strings.\n",
    "    Input parameters:\n",
    "    corpus_file - path to the corpus file\n",
    "    vocabulary_file - path to the vocabulary file\n",
    "    stopwords_file - path to the stopwords file\n",
    "    \"\"\"\n",
    "    vocabulary = np.genfromtxt(vocabulary_file,  dtype='str')\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "    corpus = []\n",
    "    \n",
    "    # read in stopwords from file into a list\n",
    "    stopwords = [] \n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stop_words = file.read().replace(',', ' ')\n",
    "        for word in stop_words.split():\n",
    "            stopwords.append(word) \n",
    "    \n",
    "    with open(corpus_file, 'r') as text:\n",
    "        doc = ''\n",
    "        new = False\n",
    "        for line in text:\n",
    "            if new: # reached a new document\n",
    "                if line.strip() != '</TEXT>': # until we reach the new doc\n",
    "                    for char in special_chars: # remove punctuation etc,\n",
    "                        line = line.replace(char, '') \n",
    "                    doc += line\n",
    "                else: # we've reached a new doc again\n",
    "                    doc = doc.lower() # all words lowercase\n",
    "                    words = np.array(doc.split())\n",
    "                    # PETER EDIT: next two lines\n",
    "                    doc = [word for word in words if (  (word not in stopwords) and (word in vocabulary)  )]\n",
    "                    corpus.append(doc)\n",
    "                    doc = ''\n",
    "            elif line.strip() == '<TEXT>': new = True\n",
    "\n",
    "    \n",
    "    return corpus, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocabulary = clean_up_data('ap/ap.txt', 'ap/vocab.txt', 'ap/stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(documents, vocabulary, k):\n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    # Initialize alpha \n",
    "    # alpha = np.ones([M,k]) * 50/k # for every document, for every topic\n",
    "    alpha = np.ones(k)*50/k\n",
    "    eta = 5/k\n",
    "    \n",
    "    Lambda = np.random.rand(k,V) * 0.5 + 0.5\n",
    "    \n",
    "    # Initialize beta\n",
    "    beta = np.zeros([k,V]) # for every topic, for every word in the vocabulary\n",
    "    for i in range(k):\n",
    "        beta[i] = np.random.uniform(0, 1, V)\n",
    "        beta[i] = beta[i] / np.sum(beta[i])\n",
    "    \n",
    "    # Initialize phi and gamma\n",
    "    phi = []\n",
    "    gamma = np.zeros([M,k]) # for every document, for every topic\n",
    "    for m in range(M):\n",
    "        doc = np.array(documents[m])\n",
    "        N = len(doc)\n",
    "        phi.append(np.ones([N,k]) * 1/float(k)) # uniform over topics\n",
    "        \n",
    "        for i in range(k):\n",
    "            gamma[m][i] = alpha[i] + N/float(k)\n",
    "        #m += 1 # WHYYYYYYY?\n",
    "        \n",
    "    return alpha, eta, beta, gamma, phi, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    k, V = beta.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        term_knvSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            \n",
    "            v = np.where(vocabulary == document[n])[0][0] # here w_n is not a vector\n",
    "            if beta[i,v] <= 0:\n",
    "                print(\"Error: beta[\"+i,v,\"]<=0\")\n",
    "            #L+= phi[n,i] * np.log(beta[i,v]) \n",
    "            term_knvSum += phi[n,i] * np.log(beta[i,v]) \n",
    "\n",
    "    #print(term0,term_knSum, term_kSum)\n",
    "    L_terms = term0 + term_knSum + term_kSum + term_knvSum\n",
    "    \n",
    "    return L_terms\n",
    "    \n",
    "\n",
    "\n",
    "def psi(gamma_i):\n",
    "    # this is the first derivative (via Taylor approximation) of the log \\Gamma function\n",
    "    # according to Wikipedia this is the \"digamma\" function\n",
    "    return scipy.special.digamma(gamma_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_lower_bound_likelihood_smoothed(k, M, V, phi, gamma, alpha, eta, document, Lambda):\\n    \\n    digamma_lambda = digamma(Lambda) - digamma(np.sum(Lambda))\\n    likelihood = 0\\n    \\n\\n    digamma_gamma = digamma(gamma) - digamma(np.sum(gamma))\\n\\n    E_theta_alpha = gammaln(alpha * k) - k * gammaln(alpha)                             + (alpha-1) * np.sum(digamma_gamma)\\n    E_z_theta = np.dot(np.sum(phi, axis = 0), digamma_gamma)\\n    E_w_z_beta = np.sum(digamma_lambda * phi)\\n    E_theta_gamma = -gammaln(np.sum(gamma)) + np.sum(gammaln(gamma))                         - np.dot(gamma - 1, digamma_gamma)\\n    E_z_phi = - np.sum(phi * np.log(phi))\\n        \\n    likelihood = E_theta_alpha + E_z_theta + E_w_z_beta + E_theta_gamma + E_z_phi\\n\\n    E_beta_eta = k * (gammaln(eta * V) - V * gammaln(eta)) k (eta - 1) * np.sum(digamma_lambda)\\n    E_beta_lambda = np.sum(gammaln(np.sum(Lambda, axis = 1)) - np.sum(gammaln(Lambda), axis = 1)[np.newaxis,:])                         + np.sum((Lambda - 1) * digamma_lambda)\\n    \\n    likelihood = np.sum(likelihood) + E_beta_eta - E_beta_lambda\\n    \\n    return(likelihood) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_lower_bound_likelihood_smoothed(phi, gamma, alpha, Lambda, document, vocabulary, k, V):\n",
    "    '''\n",
    "    This calculates the lower bound of L(gamma, phi, alpha, beta)\n",
    "    Ie. equation 15 in the paper in Appendix 3.\n",
    "    '''\n",
    "   \n",
    "    N, k = phi.shape\n",
    "    \n",
    "    loggamma_sum = lambda x: scipy.special.gammaln(np.sum(x))\n",
    "    loggamma_x_i = lambda x, i: np.log(scipy.special.gamma(x[i]))\n",
    "    E_log_thetai_givenGamma = lambda i:  (psi(gamma[i]) - psi(np.sum(gamma))) \n",
    "    E_log_betai_givenLambda = lambda i:  (psi(Lambda[i]) - psi(np.sum(Lambda))) \n",
    "\n",
    "    term0 = loggamma_sum(alpha) - loggamma_sum(gamma)\n",
    "    term_kSum=0\n",
    "    for i in range(k):\n",
    "        E = E_log_thetai_givenGamma(i)\n",
    "        term_kSum += -loggamma_x_i(alpha,i) + (alpha[i]-1) * E\n",
    "        term_kSum += gammaln(gamma[i]) - (gamma[i] - 1) * E\n",
    "\n",
    "        term_knSum = 0\n",
    "        for n in range(N):\n",
    "            if phi[n,i] == 0:\n",
    "                print(\"Error: Phi[\",n,i,\"] == 0\")\n",
    "            term_knSum += phi[n,i] * E_log_thetai_givenGamma(i)\n",
    "            term_knSum += - phi[n,i] * np.log(phi[n,i])\n",
    "            term_knSum += phi[n,i] * E_log_betai_givenLambda(i)\n",
    "\n",
    "    #print(term0,term_knSum, term_kSum)\n",
    "    L_terms = term0 + term_knSum + term_kSum \n",
    "    \n",
    "    return L_terms\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def compute_lower_bound_likelihood_smoothed(k, M, V, phi, gamma, alpha, eta, document, Lambda):\n",
    "    \n",
    "    digamma_lambda = digamma(Lambda) - digamma(np.sum(Lambda))\n",
    "    likelihood = 0\n",
    "    \n",
    "\n",
    "    digamma_gamma = digamma(gamma) - digamma(np.sum(gamma))\n",
    "\n",
    "    E_theta_alpha = gammaln(alpha * k) - k * gammaln(alpha) \\\n",
    "                            + (alpha-1) * np.sum(digamma_gamma)\n",
    "    E_z_theta = np.dot(np.sum(phi, axis = 0), digamma_gamma)\n",
    "    E_w_z_beta = np.sum(digamma_lambda * phi)\n",
    "    E_theta_gamma = -gammaln(np.sum(gamma)) + np.sum(gammaln(gamma)) \\\n",
    "                        - np.dot(gamma - 1, digamma_gamma)\n",
    "    E_z_phi = - np.sum(phi * np.log(phi))\n",
    "        \n",
    "    likelihood = E_theta_alpha + E_z_theta + E_w_z_beta + E_theta_gamma + E_z_phi\n",
    "\n",
    "    E_beta_eta = k * (gammaln(eta * V) - V * gammaln(eta)) k (eta - 1) * np.sum(digamma_lambda)\n",
    "    E_beta_lambda = np.sum(gammaln(np.sum(Lambda, axis = 1)) - np.sum(gammaln(Lambda), axis = 1)[np.newaxis,:]) \\\n",
    "                        + np.sum((Lambda - 1) * digamma_lambda)\n",
    "    \n",
    "    likelihood = np.sum(likelihood) + E_beta_eta - E_beta_lambda\n",
    "    \n",
    "    return(likelihood) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma(k, phi, gamma, alpha, beta, document, vocabulary, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    iterations = 0\n",
    "    converged = False\n",
    "    \n",
    "    words = np.array(document)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (iterations < MAX_STEPS):\n",
    "        iterations += 1\n",
    "            \n",
    "        phi_old = phi\n",
    "        gamma_old = gamma\n",
    "            \n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                for i in range(k):                \n",
    "                    beta_ = beta[i, np.where(vocabulary == word)]\n",
    "                    phi[n, i] = beta_[0][0] * np.exp(digamma(gamma[i]) - digamma(np.sum(gamma)))\n",
    "                phi[n,:] = phi[n,:] / np.sum(phi[n,:])   \n",
    "        gamma = alpha + np.sum(phi, axis=0)    \n",
    "            \n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print(str(iterations) + ' iterations to converge.')\n",
    "                \n",
    "            likelihood += compute_lower_bound_likelihood(phi, gamma, alpha, beta, document, vocabulary, k)\n",
    "            converged = True\n",
    "    \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_phi_gamma_smoothed(k, M, V, phi, gamma, alpha, eta, Lambda, doc, vocabulary, document, tol=1e-5, MAX_STEPS = 100):\n",
    "    \n",
    "    likelihood = 0.0\n",
    "    iterations = 0\n",
    "    converged = False\n",
    "    \n",
    "\n",
    "    words = np.array(doc)\n",
    "    N = len(words)\n",
    "\n",
    "    while (not converged) and (iterations < MAX_STEPS):\n",
    "        iterations += 1\n",
    "            \n",
    "        #digamma_gamma = digamma(gamma) - digamma(np.sum(gamma))\n",
    "\n",
    "        phi_old = phi\n",
    "        phi = np.zeros([N,k])\n",
    "        gamma_old = gamma\n",
    "            \n",
    "        for n in range(N):\n",
    "            word = words[n]\n",
    "            if len(np.where(vocabulary == word)[0]) > 0: # word exists in vocabulary\n",
    "                for i in range(k):\n",
    "                    temp_2 = digamma(gamma[i]) - digamma(np.sum(gamma)) + digamma(Lambda[i]) - digamma(np.sum(Lambda))\n",
    "                    phi[n, i] = np.exp(temp_2)\n",
    "                phi[n,:] =  phi[n,:] / np.sum(phi[n,:] + tol)\n",
    "        gamma = alpha + np.sum(phi, axis=0) \n",
    "\n",
    "            \n",
    "            \n",
    "        \"\"\"digamma_gamma = digamma(gamma) - digamma(np.sum(gamma))\n",
    "        digamma_lambda = digamma(Lambda) - digamma(np.sum(Lambda))\n",
    "            \n",
    "        print(\"digamma_gamma\")\n",
    "        print(digamma_gamma)\n",
    "        print(\"digamma_lambda\")\n",
    "        print(digamma_lambda)\n",
    "        phi[:N,:] = digamma_gamma + digamma_lambda\n",
    "        phi[:N,:] = np.exp(phi[:N,:] - misc.logsumexp(phi[:N,:], axis = 1)[:,np.newaxis])\n",
    "            \n",
    "        gamma = alpha + np.sum(phi[:N,:], axis = 0)\"\"\"\n",
    "\n",
    "\n",
    "        # Convergence ctierion: did phi and gamma change significantly?\n",
    "        if (np.linalg.norm(phi - phi_old) < tol) and (np.linalg.norm(gamma - gamma_old) < tol):              \n",
    "            print(str(iterations) + ' iterations to converge.')\n",
    "\n",
    "            likelihood += compute_lower_bound_likelihood_smoothed(phi, gamma, alpha, Lambda, document, vocabulary, k, V)\n",
    "            converged = True\n",
    "\n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(phi, eta, Lambda, doc, vocabulary, k):\n",
    "    \n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    words = np.array(doc)\n",
    "    phi_m = phi\n",
    "    for i in range(k):\n",
    "        phi_ = phi_m[:,i]\n",
    "        for j in range(V):\n",
    "            word = vocabulary[j]\n",
    "            indicator = np.in1d(words, word)\n",
    "            indicator.astype(int)  \n",
    "            Lambda[i][j] += np.dot(indicator, phi_) \n",
    "\n",
    "    return Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(phi, documents, vocabulary, k):\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = np.zeros([k, V])\n",
    "    for m, doc in enumerate(documents):\n",
    "        words = np.array(doc)\n",
    "        phi_m = phi[m]\n",
    "        for i in range(k):\n",
    "            phi_ = phi_m[:,i]\n",
    "            for j in range(V):\n",
    "                word = vocabulary[j]\n",
    "                indicator = np.in1d(words, word)\n",
    "                indicator.astype(int) \n",
    "                beta[i][j] += np.dot(indicator, phi_)\n",
    "    beta = np.transpose(np.transpose(beta) / np.sum(beta, axis=1))\n",
    "\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha, gamma, k, M, max_iter=50, tol=1e-4):\n",
    "    \n",
    "    # Maria B version\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = M * (k * special.polygamma(1, alpha) - special.polygamma(1, k*alpha))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = M * k * (k * special.polygamma(2, k*alpha) - special.polygamma(2, alpha))\n",
    "\n",
    "    temp = gradient / (hessian * alpha + gradient + tol)\n",
    "    if (alpha == 0).any():\n",
    "        alpha += 0.005\n",
    "\n",
    "    log_alpha = np.log(alpha) - temp\n",
    "    alpha = np.exp(log_alpha)    \n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eta(eta, gamma, k, V, M, max_iter=50, tol=1e-4):\n",
    "\n",
    "    temp = 0\n",
    "    for d in range(M):\n",
    "        temp_1 = np.sum(special.polygamma(0, gamma[d])) - np.sum(special.polygamma(0, np.sum(gamma, axis=1)))\n",
    "    \n",
    "    gradient = V * (k * special.polygamma(1, eta) - special.polygamma(1, k*eta))\n",
    "    gradient = gradient + temp\n",
    "\n",
    "    hessian = V * k * (k * special.polygamma(2, k*eta) - special.polygamma(2, eta))\n",
    "\n",
    "    temp = gradient / (hessian * eta + gradient + tol)\n",
    "    if (eta == 0):\n",
    "        eta += 0.005\n",
    "\n",
    "    log_eta = np.log(eta) - temp\n",
    "    eta = np.exp(log_eta)    \n",
    "        \n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(phi, gamma, alpha, beta, documents, vocabulary, k):\n",
    "    print('E-step')\n",
    "    \n",
    "    for d, doc in enumerate(documents):\n",
    "        phi[d], gamma[d], likelihood = update_phi_gamma(k, phi[d], gamma[d], alpha, beta, doc, vocabulary)\n",
    "                \n",
    "    return phi, gamma, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step_smoothed(phi, gamma, alpha, eta, Lambda, documents, vocabulary, k):\n",
    "    print('E-step')\n",
    "    \n",
    "    V = len(vocabulary)\n",
    "\n",
    "    for d, doc in enumerate(documents):\n",
    "        print(\"Lambda\")\n",
    "        print(Lambda)\n",
    "        \n",
    "        print(\"Lambda d\")\n",
    "        print(Lambda[d])\n",
    "        \n",
    "        \n",
    "        phi[d], gamma[d], likelihood = update_phi_gamma_smoothed(k, M, V, phi[d], gamma[d], alpha, eta, Lambda, doc, vocabulary, Lambda)\n",
    "        Lambda = update_lambda(phi[d], eta, Lambda, doc, vocabulary, k)\n",
    "        \n",
    "    return phi, gamma, Lambda, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(phi, gamma, alpha, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "    \n",
    "    beta = update_beta(phi, documents, vocabulary, k)\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k):\n",
    "    print('M-step')\n",
    "    \n",
    "    M = len(documents)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    alpha = update_alpha(alpha, gamma, k, M)\n",
    "    eta = update_eta(eta, gamma, k, V, M)\n",
    "\n",
    "    return alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM(phi_init, gamma_init, alpha_init, beta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "    \n",
    "        phi, gamma, likelihood = \\\n",
    "            E_step(phi_old, gamma_old, alpha_old, beta_old, documents, vocabulary, k)\n",
    "        alpha, Beta = \\\n",
    "            M_step(phi, gamma, alpha_old, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood-likelihood_old)/likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, alpha, Beta, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, documents, vocabulary, k, tol=1e-5):\n",
    "    print('Variational EM')\n",
    "    \n",
    "    M = len(documents)\n",
    "    \n",
    "    likelihood = 0\n",
    "    likelihood_old = 0.000004\n",
    "    \n",
    "    iteration = 1 # Initialization step is the first step\n",
    "    \n",
    "    phi = phi_init\n",
    "    gamma = gamma_init\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    Lambda = Lambda_init\n",
    "    eta = eta_init\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while (not converged):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Update parameters \n",
    "        if likelihood == 0:\n",
    "            print(\"Likelihood==0\")\n",
    "            likelihood_old = 0.005\n",
    "        else:\n",
    "            likelihood_old = likelihood\n",
    "        phi_old = phi \n",
    "        gamma_old = gamma \n",
    "        alpha_old = alpha\n",
    "        beta_old = beta\n",
    "        Lambda_old = Lambda\n",
    "        eta_old = eta\n",
    "        \n",
    "    \n",
    "        phi, gamma, Lambda, likelihood = \\\n",
    "            E_step_smoothed( phi_old, gamma_old, alpha_old, eta_old, Lambda_old, documents, vocabulary, k)\n",
    "        alpha, eta = \\\n",
    "            M_step_smoothed(phi, gamma, alpha, eta, documents, vocabulary, k)\n",
    "                \n",
    "        if iteration > 15:\n",
    "            break\n",
    "        \n",
    "        # check convergence\n",
    "        if (np.abs((likelihood - likelihood_old) / likelihood_old) > tol):\n",
    "            if (iteration > 2):\n",
    "                converged = True\n",
    "        \n",
    "    return phi, gamma, Lambda, alpha, eta, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "corpus_reduced = corpus[:4]\n",
    "M = len(corpus_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "E-step\n",
      "40 iterations to converge.\n",
      "44 iterations to converge.\n",
      "47 iterations to converge.\n",
      "M-step\n",
      "E-step\n",
      "45 iterations to converge.\n",
      "51 iterations to converge.\n",
      "56 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "phi, gamma, alpha, beta, likelihood = \\\n",
    "        variational_EM(phi_init, gamma_init, alpha_init, beta_init, corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: smoothed LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init, eta_init, beta_init, gamma_init, phi_init, Lambda_init = initialize_parameters(corpus_reduced, vocabulary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93482026, 0.61994665, 0.93604265, ..., 0.58347216, 0.56558451,\n",
       "        0.84597367],\n",
       "       [0.83004493, 0.52587452, 0.68721003, ..., 0.83636801, 0.67649382,\n",
       "        0.69082077],\n",
       "       [0.97500146, 0.58593848, 0.66356622, ..., 0.62234055, 0.78606509,\n",
       "        0.67990884]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "E-step\n",
      "Lambda\n",
      "[[0.93482026 0.61994665 0.93604265 ... 0.58347216 0.56558451 0.84597367]\n",
      " [0.83004493 0.52587452 0.68721003 ... 0.83636801 0.67649382 0.69082077]\n",
      " [0.97500146 0.58593848 0.66356622 ... 0.62234055 0.78606509 0.67990884]]\n",
      "Lambda d\n",
      "[0.93482026 0.61994665 0.93604265 ... 0.58347216 0.56558451 0.84597367]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-683eb4fd2ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvariational_EM_smoothed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_reduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-97ec5661fc54>\u001b[0m in \u001b[0;36mvariational_EM_smoothed\u001b[1;34m(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, documents, vocabulary, k, tol)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mE_step_smoothed\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mphi_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mM_step_smoothed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-d73a45c4bd6e>\u001b[0m in \u001b[0;36mE_step_smoothed\u001b[1;34m(phi, gamma, alpha, eta, Lambda, documents, vocabulary, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_phi_gamma_smoothed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_lambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-9df592d08ef4>\u001b[0m in \u001b[0;36mupdate_phi_gamma_smoothed\u001b[1;34m(k, M, V, phi, gamma, alpha, eta, Lambda, doc, vocabulary, document, tol, MAX_STEPS)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[0mtemp_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "phi, gamma, Lambda, alpha, eta, likelihood = \\\n",
    "variational_EM_smoothed(phi_init, gamma_init, alpha_init, beta_init, Lambda_init, eta_init, corpus_reduced, vocabulary, k, tol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x154979ff710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(gamma.T)\n",
    "plt.xlabel(\"Documents\")\n",
    "plt.ylabel(\"topic 1..k\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolormesh(Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liberace', 'museum', 'mrs', 'police', 'shot']\n",
      "['israel', 'rappaport', 'bechtel', 'official', 'peres']\n",
      "['museum', 'peres', 'mrs', 'offer', 'police']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(k):\n",
    "    beta_topic = beta[l,:]\n",
    "    beta_topic_top4 = np.argsort(beta_topic)[-5:]\n",
    "    plt.plot(beta_topic)\n",
    "    print([w for w in np.array(vocabulary)[beta_topic_top4][:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TEXT WITH COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For three years Charles S Robb was out of the spotlight that had become so familiar first as the soninlaw of President Lyndon Johnson and then as Democratic governor of this conservative state But on Tuesday the yearold lawyer reentered the national arena in decisive style fashioning a huge victory over Republican longshot Maurice Dawkins a retired black minister and Washington lobbyist Robb said today he won because we attempted to identify with mainstream values that are crucial to success at the national level such as strong defense and fiscal responsibility With  percent of the precincts counted Robb had'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_text(corpus_file, number_of_text):\n",
    "    fulltext_words=[]\n",
    "    fulltext_allwords=[]\n",
    "    #number_of_text=2\n",
    "    text_counter=0\n",
    "    special_chars = '1234567890~!@#Â£$%^&*()_+,./<>?\\|\"]}\\'[{`-'\n",
    "\n",
    "    with open(corpus_file, 'r') as text:\n",
    "        new=False\n",
    "        for line in text:\n",
    "            if new:\n",
    "                #print(line.strip()[0], line.strip()[:10])\n",
    "                if line.strip()[0]==\"<\":\n",
    "                    pass\n",
    "                else:\n",
    "                    #print(\"FOUND\", text)\n",
    "                    text_counter+=1\n",
    "                    if text_counter==number_of_text:\n",
    "                        #print(\" CORRECT\")\n",
    "                        new_text=line\n",
    "                        fulltext=new_text\n",
    "                        words = np.array(new_text.split())\n",
    "                        for word in words:\n",
    "                            fulltext_allwords.append(word)\n",
    "                            for char in special_chars: # remove punctuation etc,\n",
    "                                word = word.replace(char, '') \n",
    "                            fulltext_words.append(word)\n",
    "\n",
    "\n",
    "            else:\n",
    "                if line.strip() == \"<TEXT>\":\n",
    "                    new=True\n",
    "    return fulltext_words, fulltext_allwords\n",
    "\n",
    "fulltext_words, fulltext_allwords = get_full_text('ap/ap.txt', 13)\n",
    "\" \".join(fulltext_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top= 2, "
     ]
    }
   ],
   "source": [
    "colors=['blue','green', 'red']\n",
    "fulltext_colors=[]\n",
    "\n",
    "how_significant=2.5\n",
    "significance=[]\n",
    "for word in fulltext_words:\n",
    "    if word in vocabulary:\n",
    "        v = np.where(vocabulary==word)[0][0]\n",
    "        #print(v,word_beta )\n",
    "        word_beta = beta[:,v]\n",
    "        #significance.append(np.max(word_beta)/np.mean(word_beta))\n",
    "        if np.max(word_beta)>np.mean(beta):\n",
    "            if np.max(word_beta)> how_significant*np.mean(word_beta):\n",
    "                #significance =  (np.max(word_beta) / np.mean(word_beta) > 10)\n",
    "                topic = np.where(np.max(word_beta)==word_beta)[0][0]\n",
    "                color = colors[topic]\n",
    "                print(word+\"=\",str( topic)+\", \", end=\"\")\n",
    "\n",
    "            else:\n",
    "                color='k'\n",
    "        else:\n",
    "            color='k'\n",
    "    else: \n",
    "        color='k'\n",
    "    fulltext_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mFor \u001b[0mthree \u001b[0myears, \u001b[0mCharles \u001b[0mS. \u001b[0mRobb \u001b[0mwas \u001b[0mout \u001b[0mof \u001b[0mthe \u001b[0mspotlight \u001b[0mthat \u001b[0mhad \u001b[0mbecome \u001b[0mso \u001b[0mfamiliar, \u001b[0mfirst \u001b[0mas \u001b[0mthe \u001b[0mson-in-law \u001b[0mof \u001b[0mPresident \u001b[0mLyndon \u001b[0mJohnson \u001b[0mand \u001b[0mthen \u001b[0mas \u001b[0mDemocratic \u001b[0mgovernor \u001b[0mof \u001b[0mthis \u001b[0mconservative \u001b[0mstate. \u001b[0mBut \u001b[0mon \u001b[0mTuesday, \u001b[0mthe \u001b[0m49-year-old \u001b[0mlawyer \u001b[0mre-entered \u001b[0mthe \u001b[0mnational \u001b[0marena \u001b[0min \u001b[0mdecisive \u001b[0mstyle, \u001b[0mfashioning \u001b[0ma \u001b[0mhuge \u001b[0mvictory \u001b[0mover \u001b[0mRepublican \u001b[0mlong-shot \u001b[0mMaurice \u001b[0mDawkins, \u001b[0ma \u001b[0mretired \u001b[0mblack \u001b[0mminister \u001b[0mand \u001b[0mWashington \u001b[0mlobbyist. \u001b[0mRobb \u001b[0msaid \u001b[0mtoday \u001b[0mhe \u001b[0mwon \u001b[0mbecause \u001b[0m``we \u001b[0mattempted \u001b[0mto \u001b[0midentify \u001b[0mwith \u001b[0mmainstream \u001b[0mvalues \u001b[0mthat \u001b[0mare \u001b[0mcrucial \u001b[0mto \u001b[0msuccess \u001b[0mat \u001b[0mthe \u001b[0mnational \u001b[0mlevel,'' \u001b[0msuch \u001b[0mas \u001b[0mstrong \u001b[0mdefense \u001b[0mand \u001b[0mfiscal \u001b[0mresponsibility. \u001b[0mWith \u001b[0m99 \u001b[0mpercent \u001b[0mof \u001b[0mthe \u001b[0mprecincts \u001b[0mcounted, \u001b[0mRobb \u001b[0mhad \u001b[0m1,448,389 \u001b[0mvotes \u001b[0mor \u001b[0m71 \u001b[0mpercent, \u001b[0mto \u001b[0mDawkins' \u001b[0m587,887 \u001b[0mvotes \u001b[0mor \u001b[0m29 \u001b[0mpercent. \u001b[0mThe \u001b[0mformer \u001b[0mMarine \u001b[0mcombat \u001b[0mofficer \u001b[0mhas \u001b[0mbuilt \u001b[0ma \u001b[0mcareer \u001b[0mby \u001b[0mmaking \u001b[0mDemocrats \u001b[0melectable \u001b[0min \u001b[0mconservative \u001b[0mVirginia. \u001b[0mOnce \u001b[0mknown \u001b[0monly \u001b[0mas \u001b[0mthe \u001b[0mformer \u001b[0mWhite \u001b[0mHouse \u001b[0mmilitary \u001b[0msocial \u001b[0maide \u001b[0mwho \u001b[0mmarried \u001b[0mLBJ's \u001b[0mdaughter, \u001b[0mLynda \u001b[0mBird \u001b[0mJohnson, \u001b[0mhe \u001b[0mwon \u001b[0mthe \u001b[0mlieutenant \u001b[0mgovernor's \u001b[0mrace \u001b[0min \u001b[0m1977 \u001b[0min \u001b[0mhis \u001b[0mfirst \u001b[0mbid \u001b[0mfor \u001b[0melective \u001b[0moffice. \u001b[0mFour \u001b[0myears \u001b[0mlater, \u001b[0mhe \u001b[0mran \u001b[0mfor \u001b[0mgovernor \u001b[0min \u001b[0mthe \u001b[0mfirst \u001b[0msweep \u001b[0mby \u001b[0mDemocrats \u001b[0mof \u001b[0mthe \u001b[0mstate's \u001b[0;31;48mtop \u001b[0mthree \u001b[0moffices \u001b[0msince \u001b[0m1965. \u001b[0mRobb \u001b[0mwas \u001b[0ma \u001b[0mpopular \u001b[0mgovernor \u001b[0mwho \u001b[0mwas \u001b[0mcredited \u001b[0mwith \u001b[0moverhauling \u001b[0mthe \u001b[0mstate \u001b[0mbureaucracy \u001b[0mand \u001b[0mmaking \u001b[0mmajor \u001b[0mgains \u001b[0min \u001b[0meducation \u001b[0mfunding. \u001b[0mHe \u001b[0malso \u001b[0mopened \u001b[0mpositions \u001b[0mof \u001b[0mauthority \u001b[0min \u001b[0mstate \u001b[0mgovernment \u001b[0mto \u001b[0mblacks \u001b[0mand \u001b[0mwomen \u001b[0mand \u001b[0mappointed \u001b[0mVirginia's \u001b[0mfirst \u001b[0mblack \u001b[0mSupreme \u001b[0mCourt \u001b[0mmember. \u001b[0mThe \u001b[0mformer \u001b[0mgovernor \u001b[0mwas \u001b[0malso \u001b[0mone \u001b[0mof \u001b[0mthe \u001b[0marchitects \u001b[0mof \u001b[0mlast \u001b[0mspring's \u001b[0mSuper \u001b[0mTuesday \u001b[0mpresidential \u001b[0mprimary, \u001b[0mintended \u001b[0min \u001b[0mpart \u001b[0mto \u001b[0mgive \u001b[0mthe \u001b[0mSouthern \u001b[0mvote \u001b[0mcollective \u001b[0mstrength. \u001b[0mBut \u001b[0mRobb's \u001b[0mtenure \u001b[0mwas \u001b[0mshaken \u001b[0mby \u001b[0mprison \u001b[0mtroubles \u001b[0mthat \u001b[0mdrew \u001b[0mnational \u001b[0mattention \u001b[0mwhen \u001b[0msix \u001b[0mdeath \u001b[0mrow \u001b[0minmates \u001b[0mescaped \u001b[0min \u001b[0mMay \u001b[0m1984. \u001b[0mRobb, \u001b[0mwho \u001b[0mcould \u001b[0mnot \u001b[0msucceed \u001b[0mhimself \u001b[0munder \u001b[0mVirginia's \u001b[0mconstitution, \u001b[0mhad \u001b[0mbeen \u001b[0mout \u001b[0mof \u001b[0moffice \u001b[0mfor \u001b[0mthree \u001b[0myears \u001b[0mand \u001b[0mpracticing \u001b[0mlaw \u001b[0muntil \u001b[0mhis \u001b[0mbid \u001b[0mfor \u001b[0mthe \u001b[0mSenate. \u001b[0m``I've \u001b[0mbeen \u001b[0munemployed \u001b[0mfor \u001b[0ma \u001b[0mlong \u001b[0mtime, \u001b[0mand \u001b[0mit \u001b[0mlooks \u001b[0mlike \u001b[0mI \u001b[0mjust \u001b[0mgot \u001b[0ma \u001b[0mjob,'' \u001b[0mhe \u001b[0msaid. "
     ]
    }
   ],
   "source": [
    "#http://ozzmaker.com/add-colour-to-text-in-python/\n",
    "#print(\"Examples of how to use ANSI COLOR: \\033[1;37;40m White          \\033[0m 1;37;40m            \\033[0;37;40m Light Grey \\033[0m 0;37;40m               \\033[0;37;48m Black      \\033[0m 0;37;48m\")\n",
    "colors_ansi=[34, 32,31] #blue, green, red\n",
    "             \n",
    "             \n",
    "for a in range(len(fulltext_allwords)):\n",
    "    if fulltext_colors[a]=='k':\n",
    "        #IF WE WANT TO FOCUS ON THE TOPIC WORDS:\n",
    "        #print(\"\\033[0;37;48m\"+fulltext_allwords[a], end=\" \")\n",
    "        print(\"\\033[0m\"+fulltext_allwords[a], end=\" \")\n",
    "        \n",
    "        #print(fulltext_allwords[a], end=\" \")\n",
    "    else:\n",
    "        for j in range(k):\n",
    "             if fulltext_colors[a]==colors[j]:\n",
    "                print(\"\\033[0;\"+str(colors_ansi[j])+\";48m\"+fulltext_allwords[a], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mTOPIC: 0: \u001b[0;34;48m\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 1: \u001b[0;32;48m\n",
      "\u001b[0m\n",
      "\u001b[0mTOPIC: 2: \u001b[0;31;48mtop\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topic_words =[]\n",
    "for i in range(k):\n",
    "    topic_words.append(np.where(np.array(fulltext_colors)==colors[i]))\n",
    "    print(\"\\033[0mTOPIC: \"+str(i)+\": \"+\"\\033[0;\"+str(colors_ansi[i])+\";48m\"+ \", \".join(np.array(fulltext_words)[topic_words[i]]))\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REUTERS DATA (get from the external program to keep this a bit tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\bjeli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_max_reuters =  7769\n",
      "We have  100  Documents with sizes:  [633, 259, 119, 155, 115, 34, 250, 83, 182, 133, 126, 85, 84, 111, 99, 101, 67, 26, 73, 140, 108, 173, 49, 236, 109, 111, 365, 42, 66, 49, 130, 90, 52, 21, 136, 14, 28, 102, 110, 67, 72, 143, 196, 31, 24, 34, 601, 32, 123, 958, 193, 118, 36, 55, 54, 113, 36, 67, 569, 25, 100, 185, 60, 145, 78, 61, 10, 87, 252, 61, 151, 466, 128, 44, 25, 179, 180, 54, 167, 42, 76, 114, 301, 506, 78, 83, 51, 111, 254, 10, 136, 186, 127, 145, 85, 34, 34, 91, 68, 77]\n"
     ]
    }
   ],
   "source": [
    "from getReuters import D_reuters as corpus_reuters\n",
    "from getReuters import vocab_list as vocabulary_reuters\n",
    "vocabulary_reuters=np.array(vocabulary_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_reuters = 2\n",
    "corpus_reuters_reduced = corpus_reuters[:10]\n",
    "M_reuters = len(corpus_reuters_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "alpha_init_reuters, eta_init_reuters, beta_init_reuters, gamma_init_reuters, phi_init_reuters, Lambda_init_reuters =\\\n",
    "    initialize_parameters(corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational EM\n",
      "Likelihood==0\n",
      "E-step\n",
      "42 iterations to converge.\n",
      "29 iterations to converge.\n",
      "17 iterations to converge.\n",
      "21 iterations to converge.\n",
      "18 iterations to converge.\n",
      "9 iterations to converge.\n",
      "20 iterations to converge.\n",
      "13 iterations to converge.\n",
      "21 iterations to converge.\n",
      "20 iterations to converge.\n",
      "M-step\n",
      "E-step\n",
      "47 iterations to converge.\n",
      "36 iterations to converge.\n",
      "21 iterations to converge.\n",
      "25 iterations to converge.\n",
      "21 iterations to converge.\n",
      "11 iterations to converge.\n",
      "23 iterations to converge.\n",
      "16 iterations to converge.\n",
      "25 iterations to converge.\n",
      "26 iterations to converge.\n",
      "M-step\n"
     ]
    }
   ],
   "source": [
    "Phi_reuters, gamma_reuters, alpha_reuters, Beta_reuters, likelihood_reuters = \\\n",
    "        variational_EM(phi_init_reuters, gamma_init_reuters, alpha_init_reuters, beta_init_reuters, \n",
    "                       corpus_reuters_reduced, vocabulary_reuters, k_reuters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Analysis for REUTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1549deea438>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(Beta_reuters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
